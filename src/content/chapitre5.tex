\chapter{Une architecture d'habitats intelligents distribuée}
\label{chap:5}

\section{Introduction}

Il a été vu, dans les chapitres précédents qu'au fil des ans, diverses architectures de maisons intelligentes ont été proposées et mises en place au sein de laboratoires ou dans de réelles habitations pour mener des activités de recherche \citep{DJCook2003,Helal2005,Giroux2009,Cook2013,Bouchard2014,Lago2017,Plantevin2018}. Ces travaux se sont particulièrement intéressés à l'utilisation de capteurs, d'effecteurs et de techniques d'apprentissage machine pour la mise en application de l'\acl{IAm} comme méthode empirique afin de soutenir l'autonomie des personnes âgées et le suivi de la santé. Cependant, bien que chacun de ces travaux se distingue des autres, tous proposent différentes méthodes pour résoudre le problème principal de la reconnaissance d'activités. Les avantages et les inconvénients de chaque architecture d'habitats intelligents ont déjà été discutés dans cette thèse et le principal problème qui a été identifié réside dans le manque de fiabilité et l'évolutivité de ces implémentations. En effet, la plupart des architectures admettent au moins un point de défaillance unique (\acl{SPOF} ou \acs{SPOF}) principalement à cause de leur implémentation centralisée, ou monolithique. Néanmoins, \cite{Plantevin2018} ont adressé cette problématique en introduisant un nouveau type d'architecture basée sur l'utilisation de transducteurs intelligents distribués. Cependant, bien que cette implémentation ait été pensée pour être une architecture de maisons intelligentes prête à l'emploi en situation réelle d'utilisation, sa conception ne semble pas suffisamment adaptée aux environnements de recherche. En effet, la simplicité de mise en place de nouvelles méthodes pour la reconnaissance d'activités et de nouveaux protocoles expérimentaux semble avoir été oubliés dans cette implémentation.

Par ailleurs, dans la comparaison des différentes architectures de maisons intelligentes proposées au chapitre \ref{chap:2}, le principal inconvénient des solutions existantes qui a été identifié concerne leur manque de flexibilité quant à l'intégration de nouveaux matériels et plus spécifiquement, les \textit{wearable devices}. En effet, pour réaliser la reconnaissance d'activités, la plupart des méthodes proposées avec ses dispositifs sont des applications complètes. La plupart du temps, les différents processus qui composent la reconnaissance sont encapsulés au sein d'un unique composant logiciel immuable. Il devient donc difficile de les modifier. De plus, le fait de disposer d'une unique application ne favorise pas la réutilisation de certains mécanismes communs à plusieurs méthodes. Ceux-ci doivent donc généralement être soit développés à nouveau, soit adaptés afin de pouvoir supporter des modifications dans la méthode proposée. De surcroît, l'exploitation de ce genre d'application \og prête à l'emploi \fg est, la plupart du temps, complexifiée. En effet, selon les dépendances, le langage de programmation et la plateforme, elles peuvent être difficiles à adapter et à déployer d'un environnement à un autre (\textit{p. ex.} entre deux laboratoires de recherche différents).

Ainsi, ce travail présente un autre type d'architecture de maisons intelligentes qui se veut fiable et évolutive dont l'implémentation est inspirée des architectures de \textit{cloud} privées sur site. Cette architecture vise à résoudre la plupart des problèmes identifiés au sein des implémentations précédemment proposées sans qu'il soit nécessaire de remplacer leur structure au complet. En effet, l'implémentation présentée dans ce chapitre a été pensée pour à la fois être déployée en l'état, ou pour s'intégrer aux architectures existantes, remplaçant ainsi les entités centrales des architectures monolithiques. L'objectif principal de cette implémentation est alors de pouvoir y déployer facilement de nouveaux composants logiciels expérimentaux indépendamment des différences dans leur conception, tant en termes de langages de programmation que de librairies requises ou de plateforme supportées. Ceci dans le but de favoriser l'interopérabilité entre les différents processus, leur réutilisation ainsi que leur mise à l'échelle vis-à-vis de la quantité de ressources requise.

La suite de ce chapitre comporte une première section qui présente en détail l'architecture d'habitats intelligents proposée. Ensuite, les expérimentations sont décrites dans une seconde section. Finalement, ce chapitre propose une discussion des observations réalisées et dresse une conclusion quand à ce second travail, dans une dernière partie.

\section{Architecture Proposée}

Bien que l'architecture introduite dans ce chapitre ait été conçue pour être compatible avec la majorité des architectures de maisons intelligentes présentes dans la littérature, celle-ci peut surtout être considérée comme une extension du travail proposé par \cite{Plantevin2018}. En effet, puisque les auteurs ont concentré leurs efforts sur la suppression des \acsp{SPOF}, ils ont amorcé les perspectives d'amélioration de la fiabilité globale des habitats intelligents existants. Néanmoins, l'idée principale de ce travail est d'aller plus loin dans l'idée de rendre ces architectures plus fiables, mais aussi plus flexibles. Pour ce faire, ce chapitre présente une implémentation qui repose sur l'utilisation des microservices plutôt qu'une approche monolithique.

\subsection{Microservices}

Les architectures de microservices sont récemment apparues comme un nouveau paradigme pour la programmation d'applications et dont l'origine se base sur le concept d'\ac{AOS} \citep{MacKenzie2006}. Comme le montre la figure \ref{fig:mono_micro}, cette approche suggère de diviser une application en un ensemble de services plus petits, indépendants et interconnectés. En comparaison aux applications monolithiques, où tous les composants logiciels se trouvent dans une seule instance, les services exécutent des fonctions plus détaillées et précises. Bien que les architectures monolithiques soient simples à implémenter, les architectures de microservices présentent, elles aussi, différents avantages. La première concerne l'\emph{agilité} des microservices. En effet, puisque les applications sont fragmentées au niveau le plus élémentaire de leurs fonctionnalités, chaque service devient individuellement plus facile à maintenir et beaucoup plus rapide à développer et à déployer. Le second avantage principal demeure la \emph{réutilisabilité}. Les microservices permettent aux développeurs de créer des applications en utilisant certains fragments déjà existants. De plus, la barrière entre les technologies (\textit{p. ex.} les langages de programmation) est réduite puisque les services fonctionnent de manière indépendante. En ce sens, cet \emph{agnosticisme technologique} permet d'obtenir des applications hétérogènes du point de vue des technologies dans leur conception. Par ailleurs, un autre avantage offert par les architectures de microservices concerne la mise à l'échelle des différents composants à mesure que la demande pour une application augmente. En cas de forte demande ponctuelle, il est possible soit d'augmenter la quantité de ressources allouées, soit d'augmenter le nombre d'instances pour les services les plus impactés, plutôt que pour l'intégralité de application. Il s'agit respectivement de l'\emph{extensibilité dynamique horizontale} et de l'\emph{extensibilité dynamique verticale}. Enfin, puisque les composants d'une application dans une architecture de microservices sont généralement distribués, l'application est en mesure de supporter les pannes au niveau des services qui la composent. En effet, lorsqu'un service est en panne, la fonctionnalité dont il est responsable devient inopérante, mais le fonctionnement du reste de l'application n'est pas altéré. De plus, il est possible de mettre en place différents mécanismes pour remédier aux défaillances inattendues afin d'augmenter la résilience et la \emph{fiabilité} de l'ensemble du système.

\begin{figure}[t]
	\centering
	\includegraphics[width=.8\linewidth]{chapter5/mono_micro.pdf}
		\caption{Comparaison entre les architectures monolithiques et de microservices selon un exemple d'application qui vise à résoudre un problème d'apprentissage machine par le biais d'une interface graphique.}
	\label{fig:mono_micro}
\end{figure}

\begin{figure}[hb!]
	\centering
	\includegraphics[width=.8\linewidth]{chapter5/containers_vms.pdf}
		\caption{Illustration détaillée des trois principales techniques de virtualisation pour la mise en place d'une architecture de microservices.}
	\label{fig:containers_vms}
\end{figure}

Actuellement, il existe de nombreuses façons de mettre en place une architecture de microservices, la plus courante étant l'utilisation d'outils de virtualisation tels que les machines virtuelles (\acsp{VM}) traditionnelles, les conteneurs ou les conteneurs à l'intérieur de \acsp{VM}. La figure \ref{fig:containers_vms} fournit une représentation graphique de ces trois différentes implémentations. Même si le choix de la méthode de virtualisation n'affecte pas les possibilités offertes par les architectures de microservices, il existe des différences significatives entre l'utilisation de \acsp{VM} traditionnelles et les conteneurs qu'il semble important de détailler. La principale différence réside dans le fait que les conteneurs proposent une virtualisation au niveau du système d'exploitation alors que les \acsp{VM} offrent une virtualisation au niveau du matériel. En ce qui concerne les \acsp{VM}, l'hyperviseur permet de cloisonner des portions du matériel. En effet, son rôle est d'attribuer à chaque machine virtuelle les ressources nécessaires en fonction des ressources physiques du système hôte. De manière générale, il existe deux types d'hyperviseurs. Dans un premier temps, il y a les hyperviseurs de système natif qui s'exécutent directement sur le matériel du système hôte. En ce sens, ceux-ci prennent la place du système d'exploitation de l'hôte et planifient directement l'utilisation des ressources allouées aux machines virtuelles en fonction du matériel. Dans un second temps, les hyperviseurs hébergés fonctionnent comme une couche logicielle supplémentaire au sein du système d'exploitation hôte. Ainsi, ils permettent de dissocier les systèmes d'exploitation invités (virtualisés) du système d'exploitation hôte.

Alternativement, les conteneurs permettent aux instances virtuelles de partager un système d'exploitation hôte unique. Par conséquent, puisque les conteneurs n'ont pas à embarquer un système d'exploitation, les images virtualisées demeurent beaucoup plus légères que celles des \acsp{VM} traditionnelles. De plus, les conteneurs sont, au même titre que les \acsp{VM}, isolés du système hôte, c'est-à-dire, qu'ils s'exécutent dans des espaces séparés à la fois les uns des autres, mais également de certaines parties du système d'exploitation hôte. Une telle isolation permet donc une utilisation plus efficace des ressources. Enfin, les conteneurs sont très rapides à créer et à détruire puisqu'il n'est pas nécessaire de démarrer ou d'arrêter un système d'exploitation à chaque fois. En effet, les conteneurs s'occupent uniquement de compléter le processus dont ils sont en charge.

En somme, une \acs{VM} est une émulation d'un système informatique tandis que les conteneurs sont toutes les unités logiciel qui regroupent le code et toutes ses dépendances requises (\textit{p. ex.} les librairies ou les binaires) qui composent une application. De ce fait, celle-ci peut s'exécuter de façon fiable et rapide d'un environnement à un autre. Ces deux technologies ne sont pas incompatibles puisqu'il est possible de les utiliser ensemble. Cependant, l'exécution de conteneurs à l'intérieur de machines virtuelles est, la plupart du temps, le résultat de l'évolution d'environnements de virtualisation matures déjà existants. Généralement, les conteneurs sont exécutés directement sur le système hôte afin d'optimiser les performances et la latence ou de réduire les coûts des licences des outils de virtualisation et des systèmes d'exploitation.

\subsection{Organisation Matérielle}

\begin{figure}[t]
	\centering
	\includegraphics[width=.9\linewidth]{chapter5/proposed_arch.pdf}
        \caption{Organisation matérielle de l'architecture d'habitats intelligents proposée illustrant l'implémentation d'un \textit{cluster} pour le support de l'architecture de microservices ainsi que le système de fichiers distribué.}
	\label{fig:proposed_arch}
\end{figure}

L'organisation matérielle de l'implémentation de l'architecture d'habitats intelligents présentée dans ce chapitre est illustrée par la figure \ref{fig:proposed_arch}. Afin de supporter l'architecture de microservices, cette organisation repose sur un ensemble de cinq n\oe{}uds principaux (\texttt{m0}, \texttt{m1}, \texttt{m2}, \texttt{w0} et \texttt{w1}) qui forment un \textit{cluster} distribué. Par ailleurs, l'implémentation proposée suggère l'utilisation de deux n\oe{}uds supplémentaires (\texttt{f0} et \texttt{f1}) sur chacun desquels une unité de stockage de type \acs{RAID} (\acl{RAID}) est interfacée. L'objectif de ces n\oe{}uds est de fournir un système de fichiers distribué à l'ensemble du \textit{cluster}. En effet, puisque certains conteneurs ont la capacité de monter différents volumes sur le système hôte, un tel système de fichiers offre un moyen fiable de partager des données entre chaque conteneur, quel que soit le n\oe{}ud sur lequel ils s'exécutent. En outre, tous les n\oe{}uds qui composent le \textit{cluster} et le système de fichier distribué sont connectés à un commutateur réseau pour leur permettre de communiquer entre eux. De plus, l'ensemble de l'architecture est isolé à l'intérieur d'un réseau local afin de prévenir les problèmes de sécurité qui pourraient compromettre les expériences et de préserver l'anonymat des participants. Toutefois, pour faciliter la configuration et la maintenance de l'architecture, cette dernière demeure accessible de manière ad hoc avec un ordinateur \textit{via} un routeur qui est, quant a lui, connecté à la fois au Web et au réseau local.

\subsection{Système de fichiers distribué}

Le système de fichiers distribué fourni par les n\oe{}uds \texttt{f0} et \texttt{f1} repose sur le protocole \ac{NFS}. Le principe de ce protocole reste simple, car il est implémenté selon le modèle client/serveur. Un serveur \acs{NFS} gère l'authentification, l'autorisation, l'administration des clients ainsi que les données. Ainsi, une fois autorisés, les clients NFS peuvent accéder aux données distantes de la même manière qu'ils le font localement. En ce sens, chaque n\oe{}ud qui compose le \textit{cluster} est autorisé à accéder (lecture) et à manipuler les fichiers (création, mise à jour, suppression) de manière classique. Néanmoins, tous les autres n\oe{}uds seront informés des changements qui en résultent.

Cependant, puisque l'idée est de proposer une architecture fiable, le fait de n'avoir qu'un seul serveur \acs{NFS} ne satisfaisait pas cette contrainte. En ce sens, l'outil \acs{DRDB}\footnote{\url{https://www.linbit.com/drbd/}} (\acl{DRDB}) a été mis en place afin que les n\oe{}uds \texttt{f0} et \texttt{f1} puissent proposer un système de fichiers à la fois distribué, mais aussi répliqué. \acs{DRDB} a été paramétré pour effectuer une réplication complète des données stockées entre le serveur principal (\texttt{f0}) et le serveur secondaire (\texttt{f1}), soit le même fonctionnement qu'un système de stockage de type \acs{RAID} 1 en réseau. Afin de favoriser l'intégrité des données plutôt que la vitesse de réplication, la mise en place d'une réplication synchrone constante entre le n\oe{}ud principal et le n\oe{}ud secondaire a été adoptée plutôt qu'une réplication asynchrone ou semi-synchrone. Ainsi, les opérations de manipulation des fichiers réalisées sur le n\oe{}ud principal ne sont considérées comme terminées que lorsque les écritures sur le disque local et sur le disque distant du n\oe{}ud secondaire sont confirmées par ce dernier. Néanmoins, \acs{DRDB} ne fournit aucune fonctionnalité relative à un quelconque mécanisme garantissant la fiabilité du système de fichiers en cas de panne d'un des deux n\oe{}uds. En ce sens, l'outil Heartbeat\footnote{\url{http://www.linux-ha.org/doc/man-pages/re-heartbeat.html}} a également été adopté dans cette implémentation. Cet outil permet de proposer un mécanisme permettant de garantir la haute disponibilité du système de fichiers distribué. En tant que processus d'arrière-plan, le logiciel vise à surveiller l'état des deux serveurs \acs{DRDB}. En cas de défaillance du n\oe{}ud principal (\texttt{f0}), l'adresse \ac{VIP} du système de fichiers distribué qui pointe vers \texttt{f0} est automatiquement réaffectée pour identifier le n\oe{}ud secondaire (\texttt{f1}). Ainsi, l'accès aux données n'est en aucun cas compromis lors de la perte d'un seul n\oe{}ud, puisque cette opération est effectuée de manière transparente pour les clients \acs{NFS}.

\subsection{Orchestration des conteneurs}

L'implémentation de l'architecture de microservices proposée dans ce chapitre repose d'abord sur le moteur de conteneurs Docker\footnote{\url{https://www.docker.com/}}, qui a été installé sur chaque n\oe{}ud qui compose le \textit{cluster} (\texttt{m0}, \texttt{m1}, \texttt{m2}, \texttt{w0} et \texttt{w1}). De plus, afin de pouvoir mettre en place le \textit{cluster} distribué grâce à l'ensemble de ces n\oe{}uds, il était nécessaire d'utiliser un orchestrateur. L'orchestration de conteneurs fait référence à un ensemble de techniques qui permettent de gérer les différents cycles de vie des conteneurs ainsi que leurs environnements dynamiques. Plus précisément, les outils d'orchestration permettent d'automatiser plusieurs tâches telles que la configuration, l'ordonnancement, l'approvisionnement et la mise à l'échelle des conteneurs, mais également la répartition de charge, l'allocation des ressources et la sécurité des interactions entre les conteneurs. Il existe actuellement plusieurs outils d'orchestration de conteneurs populaires tels que Kubernetes\footnote{\url{https://kubernetes.io/}}, Apache Mesos\footnote{\url{https://mesos.apache.org/}} et Docker Swarm\footnote{\url{https://docs.docker.com/engine/swarm/}}. Pour notre architecture, c'est l'outil Docker Swarm qui a été adopté. Plusieurs facteurs ont motivé ce choix. Tout d'abord, cet outil est plus simple à mettre en place puisqu'il est conditionné, distribué et totalement intégré au moteur de conteneur qui est déjà utilisé. En outre, bien qu'il est considéré comme moins extensible parmi les trois outils mentionnés, celui-ci offre toutes les fonctionnalités les plus importantes requises pour créer et gérer le \textit{cluster} de cette architecture.

De manière générale, un \textit{cluster} Docker Swarm est composé de plusieurs n\oe{}uds sur lesquels le moteur Docker est installé. Ces n\oe{}uds peuvent adopter deux types de rôles\textemdash un rôle de gestionnaire (\textit{manager}) ou un rôle de travailleur (\textit{worker}). Les n\oe{}uds de type \textit{manager} sont ceux qui reçoivent les fichiers de définition des services à exécuter au sein du \textit{cluster}. De plus, les \textit{managers} distribuent les tâches qui composent ces services aux n\oe{}uds de type \textit{worker}, en fonction de leurs fichiers de définition. Ainsi, ce sont les n\oe{}uds \textit{manager} qui sont responsable de l'orchestration et de la gestion du \textit{cluster}. Dans ce contexte, les services font référence à un ensemble de tâches, c'est-à-dire des conteneurs, qui doivent s'exécuter sur les n\oe{}uds travailleurs du \textit{cluster} pour réaliser un processus donné. Néanmoins, il est tout à fait possible de définir une politique de placement manuellement. Ainsi, un service peut être soit global, soit répliqué. Lorsqu'un service est global, une unique instance est déployée sur chaque n\oe{}ud du \textit{cluster} qui est disponible, et ce, sans tenir compte de son rôle.  À l'inverse, lorsqu'un service est répliqué, il est nécessaire de préciser, dans le fichier de définition, le nombre de répliques qui doivent être déployées ainsi que le type de n\oe{}uds sur lesquelles elles seront exécutées. Un des n\oe{}uds \textit{manager} est alors en charge d'établir cette répartition. Par ailleurs, afin que les n\oe{}uds \textit{manager} puissent suivre l'évolution de l'exécution des services, les n\oe{}uds travailleurs incluent un agent dont le rôle est de rendre compte, aux \textit{managers}, de l'état des services qui lui sont attribués. Par défaut, les n\oe{}uds gestionnaires sont également des n\oe{}uds travailleurs, mais il est possible de les configurer de manière à ce qu'ils n'acceptent aucune charge de travail en plus de leurs tâches de gestion du \textit{cluster}.

En ce qui concerne les \textit{managers}, puisqu'ils représentent les n\oe{}uds les plus importants pour la stabilité du \textit{cluster}, il est nécessaire que ce dernier en comporte plusieurs. Plus précisément, préférablement un nombre impair, selon les recommandations préconisées par Docker Swarm. En effet, parmi tous les n\oe{}uds de type \textit{manager} l'un d'entre eux est élu en tant que leader par tous les autres \textit{managers} selon une implémentation de l'algorithme de consensus Raft \citep{MacKenzie2006}. Ainsi, ce n\oe{}ud particulier est responsable de toutes les décisions pour l'ensemble du groupe de \textit{managers}. Bien qu'il n'y ait pas de limite quant au nombre de n\oe{}uds gestionnaires que peut admettre un \textit{cluster} Docker Swarm, la décision concernant l'effectif à mettre en place reste un compromis entre la performance et la tolérance aux pannes. En effet, si le n\oe{}ud élu comme leader du \textit{cluster} devient indisponible, n'importe quel autre \textit{manager} peut obtenir ce rôle si le quorum Raft, c'est-à-dire, un accord majoritaire entre les n\oe{}uds gestionnaires, est possible. Plus précisément, l'algorithme Raft tolère jusqu'à $(N -1)/2$ défaillances et exige un quorum de $(N/2) + 1$ membres pour permettre une décision, où $N$ fait référence au nombre de n\oe{}uds \textit{manager}. Il apparait donc clairement qu'un tel processus peut créer une surcharge du trafic réseau avec un nombre élevé de \textit{managers}, impactant alors la performance globale du \textit{cluster}. En ce sens, nous avons opté pour un \textit{cluster} de cinq n\oe{}uds, soit trois gestionnaires et deux travailleurs. Ceci dans le but de tolérer une défaillance complète d'un n\oe{}ud, quel que soit son rôle. De plus, un tel nombre de \textit{managers} permet de respecter la contrainte d'avoir un nombre impair de n\oe{}uds gestionnaires pour que le quorum demeure toujours valide en cas de panne.

Pour permettre aux conteneurs de communiquer entre eux au sein du \textit{cluster} Docker Swarm, un pilote réseau spécifique a été utilisé. Ce pilote permet de créer des réseaux superposés (\textit{overlay networks}) en s'appuyant sur la technologie de tunnelisation \ac{VXLAN} \citep{rfc7348} qui permet l'encapsulation de trames réseau de la couche 2 dans \acs{UDP} (couche 4). Ainsi, dans un contexte de virtualisation comme celui imposé par les conteneurs, ce pilote permet de simplifier la complexité de la gestion des différents réseaux virtuels nécessaires à la communication entre les conteneurs qui sont déployés de manière éparse sur les différents n\oe{}uds du \textit{cluster}. De plus, les réseaux superposés offrent des mécanismes qui permettent de s'assurer du bon fonctionnement de la redondance d'un point de vue réseau au sein du \textit{cluster}. Lorsqu'un \textit{cluster} Docker Swarm est initialisé, un réseau \textit{ingress} est automatiquement créé sur chaque n\oe{}ud. Il s'agit d'un réseau superposé particulier dont l'objectif est de faciliter la répartition de la charge des différents services entre les n\oe{}uds du \textit{cluster}. Il est ensuite possible de créer autant de réseaux superposés que nécessaire pour interconnecter les conteneurs qui ont besoin d'échanger des données. Par ailleurs, un réseau de type pont (\textit{bridge network}) est également créé automatiquement sur chaque n\oe{}ud lors de l'initialisation du \textit{cluster}. Ces réseaux sont nécessaires pour relier tous les réseaux superposés (y compris le réseau \textit{ingress}) au réseau physique des n\oe{}uds du \textit{cluster}. Par conséquent, comme les réseaux de type pont se situent au-dessus de la couche réseau du système hôte, une communication entre les conteneurs interconnectés par un réseau superposé, mais s'exécutant dans des n\oe{}uds différents est rendue possible. Par défaut, ces communications sont chiffrées à l'aide de l'algorithme AES-GCM \citep{rfc5288}. Les n\oe{}uds \textit{manager} du cluster assurent le remplacement de la clé de chiffrement qu'ils partagent toutes les douze heures. Ceci dans le but d'assurer un niveau de sécurité acceptable sans pour autant compromettre les performances des communications réseau.

Puisque les réseaux superposés attribuent dynamiquement une adresse \acl{VIP} à chaque conteneur lors de leur création, ceux-ci sont isolés d'un point du vu réseau ce qui simplifie donc la consommation des services. Toutefois, lorsque le nombre de services devient important, il peut sembler pertinent de connaître à l'avance certaines \acsp{VIP}, ce qui n'est évidemment pas possible. Pour résoudre ce problème, l'orchestrateur Swarm propose un mécanisme de découverte de services. Cette fonctionnalité repose sur un serveur DNS qui est intégré dans le moteur de conteneur de chaque n\oe{}ud. Ce dernier est alors chargé de résoudre le nom des services pour permettre le routage des requêtes réseau vers les conteneurs correspondants grâce à leurs \acsp{VIP} associées.  En d'autres termes, le nom d'un service donné peut par exemple, être utilisé en remplacement de son adresse \acl{VIP} dans un fichier de configuration. Ainsi, cette référence est interprétée correctement grâce au processus de découverte de services dès lors que la \acs{VIP} est fixée. Néanmoins, lorsque les services sont répliqués, le mécanisme de découverte de services seul n'est plus suffisant. En ce sens, grâce à l'orchestrateur,  un mécanisme de répartition est mis en place dans le but de déterminer quelle réplique d'un service en particulier est utilisée. Ainsi, Docker Swarm s'appuie sur le protocole \ac{IPVS}, une implémentation de la répartition de charge qui est déjà intégrée au niveau de la couche réseau transport du noyau Linux. Grâce à ce protocole, les requêtes \acs{TCP}/\acs{UDP} inter-services peuvent donc être redirigée correctement vers les conteneurs appropriés. Dans le cas spécifique d'un \textit{cluster} Docker Swarm, chaque n\oe{}ud écoute sur les ports qui sont exposés par les services qui doivent être accessibles à distance depuis un environnement extérieur (\textit{p. ex.} un tableau de bord web qui écoute sur le port \texttt{8080}). Ensuite, \acs{IPVS} applique une répartition de la charge selon l'algorithme Round-Robin \citep{Ghaffarinejad2014} pour transmettre la demande à l'une des répliques actives du service en question. Comme le montre la figure \ref{fig:swarm_load_balancing}, si le n\oe{}ud sollicité ne contient aucune réplique du service demandé par un client, alors \acs{IPVS} va router la requête à une réplique active présente sur un autre n\oe{}ud, ce qui est possible grâce au réseau superposé de type \textit{ingress}.

\begin{figure}[H]
	\centering
	\includegraphics[width=.8\linewidth]{chapter5/swarm_load_balancing.pdf}
        \caption{Exemple du fonctionnement de la répartition de la charge selon l'algorithme Round-Robin appliquée par le protocole \acs{IPVS} sur lequel repose Docker Swarm où un des itinéraires possibles pour une requête faite sur le service répliqué \texttt{App} est identifié par des flèches rouges.}
	\label{fig:swarm_load_balancing}
\end{figure}

\subsection{Proxy inverse}

Puisque notre architecture est composée d'un \textit{cluster} de cinq n\oe{}uds, tous les services qui y sont déployés demeurent accessibles \textit{via} cinq points d'entrée différents, étant donné que l'orchestrateur ouvre tous ports de ces services sur chacun des n\oe{}uds du \textit{cluster}. Cependant, avec un nombre important de services, il peut s'avérer difficile de gérer quel service est publié sur quel port. Ainsi, puisque la répartition de la charge au niveau des services est réalisée \textit{via} l'orchestrateur, il semble indispensable de proposer une répartition de la charge au niveau des n\oe{}uds également. Ceci dans le but de proposer un accès externe unifié et sécurisé aux services internes par le biais d'une \acs{URL} (\acl{URL}) telle que \texttt{https://service.domain.com}. Pour ce faire, l'outil open-source Tr\ae{}fik\footnote{\url{https://traefik.io/}} a été préféré à d'autres options telles que NGINX\footnote{\url{https://www.nginx.com/}} ou HAProxy\footnote{\url{https://www.haproxy.org/}}, car il est le mieux adapté aux architectures basées sur des microservices. En effet, le principal avantage de Tr\ae{}fik est sa capacité à découvrir automatiquement les informations réseau et les services disponibles dans le \textit{cluster} et à mettre à jour dynamiquement sa configuration en fonction de l'évolution de l'environnement. Ces fonctionnalités sont particulièrement importantes avec l'utilisation de  microservices, car ceux-ci sont généralement sans état (\textit{stateless}), mais aussi, car leur durée de vie est souvent courte et de nouvelles versions peuvent avoir à être déployées fréquemment. De plus, leurs instances peuvent être mises à l'échelle de façon dynamique en fonction de l'augmentation de la demande.

Tr\ae{}fik est considéré comme un proxy inverse, c'est-à-dire, le principal point d'entrée d'un réseau privé. En effet, les proxys inverses sont, la plupart du temps, placé derrière un pare-feu et leur rôle est d'acheminer les requêtes entrantes des clients vers un des n\oe{}uds du \textit{cluster} et le service correspondant. En outre, les proxys inverses peuvent également remplir un certain nombre d'autres fonctions importantes pour améliorer l'efficacité et la sécurité des systèmes sur lesquels ils sont mis en place. Tout d'abord, en ce qui concerne Tr\ae{}fik, ce dernier fournit une répartition de la charge au niveau des n\oe{}uds ce qui permet de dispatcher les requêtes à l'ensemble des n\oe{}uds actifs au sein du \textit{cluster} pour éviter que l'un d'entre eux ne soit saturé. De plus, cet outil permet également de masquer l'organisation interne de l'architecture, car il apporte une couche supplémentaire de protection en ne dévoilant jamais l'adresse IP du n\oe{}ud qui traite réellement les requêtes. Enfin, toujours dans une optique d'offrir une meilleure protection, les proxys inverses, et plus particulièrement Tr\ae{}fik, permettent de chiffrer les échanges de données entre les clients et les services de l'architecture grâce à un ou plusieurs certificats \acs{TLS} associés aux différents services ou sous-domaines. La figure \ref{fig:arch_reverse_proxy} illustre un exemple de ce fonctionnement. En effet, Tr\ae{}fik propose un point d'entrée unique qui permet d'accéder au service \texttt{App} \textit{via} une \acs{URL} sécurisée : \texttt{https://liara.uqac.ca/app}. Ainsi lorsque cette requête est soumise par le client (\textit{p. ex. } un navigateur web), le répartiteur interne de Tr\ae{}fik achemine la requête vers l'une des répliques actives du service \texttt{App}. Dans ce scénario, la répartition de la charge fournie par l'orchestrateur Docker Swarm n'est pas représentée pour simplifier la figure, mais celle-ci demeure tout de même active et opérationnelle. En effet, bien que Tr\ae{}fik ait routé la requête vers le \texttt{n\oe{}ud 1}, il est possible que le répartiteur de charge du \textit{cluster}, quant à lui, achemine en interne la demande vers la \texttt{réplique 0} du service \texttt{App} qui s'exécute sur le \texttt{n\oe{}ud 0}.

\begin{figure}[H]
	\centering
	\includegraphics[width=.8\linewidth]{chapter5/arch_reverse_proxy.pdf}
        \caption{Exemple du fonctionnement du proxy inverse Tr\ae{}fik lorsqu'une requête pour accéder au service \texttt{App} est effectuée par un client \textit{via} une \acs{URL} sécurisée.}
	\label{fig:arch_reverse_proxy}
\end{figure}

\subsection{Gestion du \textit{cluster}}

Le moteur de conteneurs Docker incluant l'orchestrateur Docker Swarm est un outil qui est utilisé à travers une interface en ligne de commandes \acs{CLI}. Ainsi, il demeure possible d'initialiser et de gérer le \textit{cluster} Docker Swarm qui régit notre architecture selon plusieurs méthodes. La plupart du temps, la méthode d'initialisation la plus appropriée consiste en l'utilisation d'un outil de gestion de configuration tel qu'Ansible\footnote{\url{https://www.ansible.com/}} qui permet d'automatiser les tâches d'administration de systèmes. Cependant, comme notre architecture admet une taille raisonnable et demeure relativement simple, nous avons choisi d'initialiser le \textit{cluster} manuellement grâce à divers scripts shell et fichiers de configuration. En effet, alors que les outils d'automatisation offrent une meilleure gestion des flux opérationnels d'administration de systèmes complexes ainsi qu'une meilleure flexibilité globale, les scripts shell nous ont semblé être le meilleur compromis à adopter étant donné le contexte encore expérimental de cette architecture.

Par ailleurs, la gestion du \textit{cluster} au quotidien \textit{via} une interface en ligne de commandes à été jugée trop contraignante. De ce fait, le logiciel open-source Portainer\footnote{\url{https://www.portainer.io/}} a été déployé comme un service à part entière au sein du \textit{cluster}. Grâce à une interface graphique conviviale et soignée, cet outil nous a permis de simplifier considérablement la tâche de gestion du \textit{cluster}. En effet, celle-ci a permis de réduire le risque d'erreurs induit par la complexité de certaines commandes nécessaires au pilotage du moteur de conteneurs. Le choix de Portainer comme outil de gestion a été motivé par son large éventail de fonctionnalités. Les plus importantes comprennent la gestion des images, des réseaux et des volumes de conteneurs, mais cet outil propose également une visualisation des n\oe{}uds du \textit{cluster} incluant le placement de chaque conteneur, la consultation de tous les fichiers journaux de chaque conteneur ainsi que la possibilité d'augmenter ou en diminuer le nombre de répliques pour chaque service en fonction de la charge.

\subsection{Base de données répliquée}

Puisque cette architecture est conçue principalement pour les maisons intelligentes, il était important de proposer un moyen fiable de stocker les valeurs des capteurs ainsi que l'état des effecteurs. Pour ce faire, trois services ont été déployés sur le \textit{cluster}, chacun contenant une instance du \ac{SGBD} MongoDB\footnote{\url{https://www.mongodb.com/}}. Ainsi, la réplication des données a été réalisée grâce à une architecture composée d'un ensemble de répliques (\textit{replica set}) à trois membres.

MongoDB est un \acs{SGBD} open-source orienté documents et non relationnel (\acs{NoSQL}) principalement utilisé pour le stockage de gros volumes de données. Un tel choix a été fait, car sa conception est axée sur la performance, la haute disponibilité et la mise à l'échelle automatique. Puisqu'il s'agit d'un \acs{SGBD} orienté document, les données sont stockées dans des collections sous forme d'ensembles de documents. Ceux-ci font référence à une structure de données composée de paires de champs et de valeurs. En effet, ils sont formatés en \ac{BSON}, un format de fichier similaire aux objets \acs{JSON} où les champs peuvent également inclure d'autres documents, des tableaux et des ensembles de documents. Ce type de modèles de base de données dits semi-structurés impliquent qu'il n'existe pas de séparation entre les données et le schéma qui les représente. Ainsi, le principal avantage de l'approche orientée documents reste d'abord la possibilité de représenter des relations hiérarchiques complexes avec un seul enregistrement. Aussi, de tels modèles de données facilitent la répartition des données entre plusieurs n\oe{}uds de base de données, ce qui simplifie le processus de mise à l'échelle.

Dans le contexte de MongoDB, un ensemble de répliques constitue un groupe d'instances de base de données qui maintiennent le même ensemble de données en fournissant de la redondance ainsi qu'une haute disponibilité pour garantir la tolérance aux pannes. Le déploiement d'un tel ensemble peut se faire principalement selon deux types d'architectures différentes. Dans un premier cas, l'architecture est composée au minimum d'un n\oe{}ud principal et de deux n\oe{}uds secondaires. Le second type d'architecture, quant à lui, reprend les mêmes caractéristiques du premier type, mais doit également admettre un n\oe{}ud arbitre. Un n\oe{}ud principal est le seul membre d'un ensemble qui tolère les opérations d'écriture. Les n\oe{}uds secondaires sont, quant à eux, en charge de préserver une copie de l'ensemble de données du n\oe{}ud principal. Afin que le processus de réplication se déroule correctement, les n\oe{}uds secondaires appliquent les instructions du journal des opérations du n\oe{}ud principal à leur propre ensemble de données, et ce, de manière asynchrone. En revanche, dans une architecture d'ensemble de répliques qui contient un arbitre, ce dernier ne dispose pas de copie de l'ensemble de données du n\oe{}ud principal. Ainsi, le n\oe{}ud arbitre ne peut, d'aucune façon, devenir un n\oe{}ud principal en cas de panne de ce dernier. Toutefois, le n\oe{}ud arbitre participe à l'élection d'un nouveau n\oe{}ud principal lorsque cela est nécessaire. En ce sens, dans le cas d'un ensemble de répliques à trois membres, la mise en \oe{}uvre d'une architecture composée d'un n\oe{}ud principal et de deux n\oe{}uds secondaires a été préférée. En effet, le fait de remplacer un n\oe{}ud secondaire par un arbitre ne permet pas de garantir une aussi bonne répartition de la charge lors des opérations de lecture des données.

\begin{figure}[hb!]
	\centering
	\includegraphics[width=.9\linewidth]{chapter5/mongodb_replication.pdf}
        \caption{caption}
	\label{fig:mongodb_replication}
\end{figure}

La figure \ref{fig:mongodb_replication} illustre le fonctionnement de cette architecture d'ensemble de répliques composée d'un n\oe{}ud principal et de deux n\oe{}uds secondaires (P-S-S). Toutes les deux secondes, tous les n\oe{}uds s'envoient chacun des pouls (\textit{heartbeat}) et dans le cas où l'un d'entre eux ne revient pas à son émetteur dans les dix secondes, les n\oe{}uds restants identifient alors le n\oe{}ud non réactif comme inaccessible. Lorsque c'est le n\oe{}ud principal qui est indisponible, un processus d'élection est alors déclenché pour que l'un des deux n\oe{}uds secondaires devienne le nouveau n\oe{}ud principal. De la même manière que pour l'orchestration du \textit{cluster}, la recommandation qui est formulée dans la documentation pour déployer un ensemble de répliques MongoDB est de mettre en place un nombre total de n\oe{}uds impair. Ainsi, il est possible, dans le cas d'une architecture P-S-S comme celle-ci, de subir la perte totale d'une instance de la base de données. En effet, les quorums de tolérance aux pannes demeurent identiques pour les deux composants logiciels.

\subsection{Dépôt d'images de conteneurs}

Le principal avantage de l'utilisation d'une architecture de microservices, en particulier dans un environnement comme celui des laboratoires de recherche dans le domaine des habitats intelligents, est de fournir un moyen simple de déployer des composants logiciels expérimentaux qui fonctionnent dans des conteneurs pour réaliser la reconnaissance d'activités. Ainsi, dans le but de faciliter la gestion de versions (\textit{versionning}), la distribution et la réutilisation de ces composants, un système de stockage des images des conteneurs a été mise en place au sein du \textit{cluster}.

Les images sont des fichiers immuables qui sont composés de plusieurs couches contenant le code source, les librairies, les dépendances ainsi que les outils nécessaires au bon fonctionnement des conteneurs. En d'autres termes, les images décrivent les services et leur environnements virtuels à un instant donné. En fin de compte, les conteneurs ne représentent que des images qui sont en cours d'exécution. En ce sens, celles-ci peuvent être stockées dans un dépôt, où les répertoires qu'il admet contiennent les différentes versions pour chacune des images. Grâce à un tel registre, il devient possible pour les expérimentateurs de télécharger certaines images (\textit{pull}), d'en créer (\textit{push}) de nouvelles contenant leurs propre composants logiciels ou de créer de nouvelles versions d'images déjà existantes. Par défaut, le moteur de conteneurs installé sur chaque n\oe{}ud de l'architecture est configuré pour utiliser le dépôt public DockerHub\footnote{\url{https://hub.docker.com/}}. Cependant, puisque les applications expérimentales conçues dans les environnements de recherche peuvent contenir des vulnérabilités, des informations confidentielles ou un certain nombre d'innovations, la configuration du moteur de conteneurs a été modifiée afin que ce dépôt privé d'images puisse être utilisé dans le \textit{cluster}.

\subsection{Organisation des conteneurs}

Pour résumer les différents aspects qui décrivent la conception de l'architecture proposée et qui ont été introduits dans ce chapitre, la figure \ref{fig:containers} propose une représentation graphique du déploiement des conteneurs sur les n\oe{}uds qui composent le cluster. De plus, les réseaux superposés pour chaque service y sont également illustrés.

Dans ce déploiement, il est possible de voir que l'application Tr\ae{}fik admet deux services distincts. Le premier concerne le service de proxy inverse dont trois répliques sont exécutées sur chacun des n\oe{}uds de gestion du \textit{cluster} (\texttt{m0}, \texttt{m1}, \texttt{m2}). Ce placement a été privilégié, car cela permet de s'assurer de la fiabilité d'un élément aussi important en cas de perte d'un \textit{manager}. Le second service est, quant à lui, le tableau de bord web qui permet de visualiser, en temps réel, les routes actives vers les différents services ouverts à un environnement extérieur qui sont détectées par l'outil. De plus ce tableau de bord permet de visualiser plusieurs statistiques d'accès pertinentes pour l'évaluation de la charge en fonction des services. Néanmoins, puisque ce tableau de bord n'a pas un impact majeur sur le bon fonctionnement du cluster, son déploiement n'admet aucune réplique supplémentaire au seul conteneur qui lui est attribué. Toutefois, ce service est doté d'une politique de redémarrage qui prévoit de toujours relancer le conteneur si son exécution est interrompue. En ce sens, s'il se produit une défaillance au niveau du n\oe{}ud sur lequel il est déployé (\texttt{m0}), l'exécution du conteneur du tableau de bord de Tr\ae{}fik peut être relancée soit sur \texttt{m1}, soit sur \texttt{m2}. De la même manière, des instructions de déploiement identiques ont été définies pour le service du dépôt d'images et le service du tableau de bord de l'outil de gestion du \textit{cluster}. Par ailleurs, en ce qui concerne la base de données, l'ensemble de répliques MongoDB a été déployé sur les n\oe{}uds de gestion dans le but de fournir, en permanence, une réplication sûre des données et de tolérer, au maximum, la défaillance d'un unique n\oe{}ud. Enfin, puisque le rôle de l'outil Portainer est de pouvoir gérer l'intégralité du \textit{cluster}, un agent, c'est-à-dire, un service global a été déployé sur chaque n\oe{}ud pour permettre à l'application web de transmettre les bonnes requêtes aux différents moteurs de conteneurs présents sur chacun des n\oe{}uds.

En ce qui concerne la communication réseau, un réseau superposé a été créé pour chaque service. De plus, le tableau de bord du proxy inverse est automatiquement exposé et accessible \textit{via} l'\acs{URL} suivante : \texttt{https://liara.uqac.ca/proxy}. Toutefois, puisque le tableau de bord de l'outil de gestion du cluster et le dépôt d'images doivent également être accessibles depuis l'extérieur du \textit{cluster}, ces services sont connectés au réseau superposé du proxy inverse. Ainsi, le routage des demandes clients en ce qui concerne les accès à ces services est rendu possible \textit{via} les \acsp{URL} suivantes : \texttt{https://liara.uqac.ca/cluster} et \texttt{https://liara.uqac.ca/registry}.

\begin{figure}[ht!]
	\centering
	\includegraphics[width=.9\linewidth]{chapter5/containers.pdf}
        \caption{Illustration du déploiement des conteneurs sur les n\oe{}uds du \textit{cluster} qui décrivent la conception de l'architecture proposée.}
	\label{fig:containers}
\end{figure}

\section{Experimentations}

\subsection{Installation Matérielle}

\subsection{Haute disponibilité}

\section{Conclusion}