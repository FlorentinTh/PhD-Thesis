\chapter{Une architecture d'habitats intelligents distribuée}
\label{chap:5}

\hl{Grâce aux chapitres précédents, il a été vu que les \textit{wearable devices} sont de plus en plus utilisés dans le processus de reconnaissance d'activités au sein des habitats intelligents. Aussi, ces dispositifs ont également été employés dans l'objectif de répondre à plusieurs autres problématiques concrètes, comme la méthode de reconnaissance des types de sols qui été présentée au Chapitre} \ref{chap:4}\hl{, qui sont relatives à l'assistance des résidents de ces habitats, au sens large. Néanmoins, l'engouement croissant pour ces dispositifs a permis d'identifier plusieurs problématiques quant à leur utilisation dans ce contexte de recherche particulier. En effet, nous avons été en mesure d'identifier que la plupart des différentes architectures d'habitats intelligents qui ont été proposées antérieurement n'ont pas été développées dans une optique évolutive. Lorsqu'une intégration matérielle des \textit{wearable device} s'est montré facilement réalisable, comme dans l'architecture CASAS} \citep{Cook2013}\hl{, cela était au détriment de la fiabilité du processus de la reconnaissance d'activités principalement affectée par une conception d'habitat admettant plusieurs points de défaillance. Par conséquent, la principale question de recherche qui est traitée dans ce chapitre est : \textit{\og comment faire évoluer les architectures de maisons intelligentes pour leur permettre de mieux s'adapter aux divers types de capteurs (ambiants et \textit{wearable devices}) tout en garantissant un excellent niveau de fiabilité dans l'accomplissement des différents processus d'apprentissage ? \fg}.

Pour répondre à cette question, le travail présenté dans ce chapitre propose un type différent d'architecture de maisons intelligentes. Cette implémentation a été développée en s'inspirant des architectures de \textit{cloud} privées sur site qui disposent de nombreux mécanismes qui permettent de s'assurer que l'infrastructure matérielle demeure hautement disponible, ceci dans le but de garantir à la fois un excellent niveau de fiabilité, mais également une évolutivité notoire. Ainsi, cette architecture vise à résoudre la plupart des problèmes identifiés au sein des habitats précédemment proposés sans qu'il soit nécessaire de remplacer leur structure matérielle dans leur intégralité. En effet, l'architecture présentée dans ce chapitre a été pensée pour à la fois être déployée en l'état, ou pour s'intégrer à celles existantes, remplaçant ainsi les entités centrales des architectures monolithiques.}

La suite de ce chapitre comporte une première section qui présente en détail l'architecture d'habitats intelligents proposée. Ensuite, les expérimentations sont décrites dans une seconde section. Finalement, ce chapitre propose une discussion des observations réalisées et dresse une conclusion quant à ce second travail, dans une dernière partie.

% Il a été vu, dans les chapitres précédents qu'au fil des ans, diverses architectures de maisons intelligentes ont été proposées et mises en place au sein de laboratoires ou dans de réelles habitations pour mener des activités de recherche \citep{DJCook2003,Helal2005,Giroux2009,Cook2013,Bouchard2014,Lago2017,Plantevin2018}. Ces travaux se sont particulièrement intéressés à l'utilisation de capteurs, d'effecteurs et de techniques d'apprentissage machine pour la mise en application de l'\acl{IAm} comme méthode empirique afin de soutenir l'autonomie des personnes âgées et le suivi de la santé. Cependant, bien que chacun de ces travaux se distingue des autres, tous proposent différentes méthodes pour résoudre le problème principal de la reconnaissance d'activités. Les avantages et les inconvénients de chaque architecture d'habitats intelligents ont déjà été discutés dans cette thèse et le principal problème qui a été identifié réside dans le manque de fiabilité et l'évolutivité de ces implémentations. En effet, la plupart des architectures admettent au moins un point de défaillance, principalement à cause de leur implémentation centralisée, ou monolithique. Néanmoins, \cite{Plantevin2018} ont adressé cette problématique en introduisant un nouveau type d'architecture basée sur l'utilisation de transducteurs intelligents distribués. Cependant, bien que cette implémentation ait été pensée pour être une architecture de maisons intelligentes prête à l'emploi en situation réelle d'utilisation, sa conception ne semble pas suffisamment adaptée aux environnements de recherche. En effet, la simplicité de mise en place de nouvelles méthodes pour la reconnaissance d'activités et de nouveaux protocoles expérimentaux semble avoir été oubliés dans cette implémentation.

% Par ailleurs, dans la comparaison des différentes architectures de maisons intelligentes proposées au Chapitre \ref{chap:2}, le principal inconvénient des solutions existantes qui a été identifié concerne leur manque de flexibilité quant à l'intégration de nouveaux matériels et plus spécifiquement, les \textit{wearable devices}. En effet, pour réaliser la reconnaissance d'activités, la plupart des méthodes proposées avec ces dispositifs sont des applications complètes. La plupart du temps, les différents processus qui composent la reconnaissance sont encapsulés au sein d'un unique composant logiciel immuable. Il devient donc difficile de les modifier. De plus, le fait de disposer d'une unique application ne favorise pas la réutilisation de certains mécanismes communs à plusieurs méthodes. Ceux-ci doivent donc généralement être soit développés à nouveau, soit adaptés afin de pouvoir supporter des modifications dans la méthode proposée. De surcroît, l'exploitation de ce genre d'application \og prête à l'emploi \fg est, la plupart du temps, complexifiée. En effet, selon les dépendances, le langage de programmation et la plateforme, elles peuvent être difficiles à adapter et à déployer d'un environnement à un autre (\textit{p. ex.} entre deux laboratoires de recherche différents).

% Ainsi, ce travail présente un autre type d'architecture de maisons intelligentes qui se veut fiable et évolutive dont l'implémentation est inspirée des architectures de \textit{cloud} privées sur site. Cette architecture vise à résoudre la plupart des problèmes identifiés au sein des implémentations précédemment proposées sans qu'il soit nécessaire de remplacer leur structure au complet. En effet, l'implémentation présentée dans ce chapitre a été pensée pour à la fois être déployée en l'état, ou pour s'intégrer aux architectures existantes, remplaçant ainsi les entités centrales des architectures monolithiques. L'objectif principal de cette implémentation est alors de pouvoir y déployer facilement de nouveaux composants logiciels expérimentaux indépendamment des différences dans leur conception, tant en termes de langages de programmation que de librairies requises ou de plateforme supportées. Ceci dans le but de favoriser l'interopérabilité entre les différents processus, leur réutilisation ainsi que leur mise à l'échelle vis-à-vis de la quantité de ressources requise.

% La suite de ce chapitre comporte une première section qui présente en détail l'architecture d'habitats intelligents proposée. Ensuite, les expérimentations sont décrites dans une seconde section. Finalement, ce chapitre propose une discussion des observations réalisées et dresse une conclusion quand à ce second travail, dans une dernière partie.

\section{Architecture Proposée}

Bien que l'architecture introduite dans ce chapitre ait été conçue pour être compatible avec la majorité des architectures de maisons intelligentes présentes dans la littérature, celle-ci peut surtout être considérée comme une \hl{évolution} du travail proposé par \cite{Plantevin2018}. \hl{En effet, puisque les auteurs ont concentré leurs efforts sur une intégration matérielle uniforme des transducteurs (capteurs et effecteurs), ils ont amorcé les mêmes perspectives d'amélioration des habitats intelligents existants en se penchant principalement sur les capteurs ambiants. Par conséquent, cette thèse ne prendra pas en considération ce type de capteurs, mais va plutôt traiter exclusivement des \textit{wearable devices}}. De plus, l'objectif principal de ce travail est d'aller plus loin dans l'idée de rendre ces architectures plus fiables, mais aussi plus flexibles et évolutives. Pour ce faire, ce chapitre présente une implémentation qui repose sur l'utilisation des microservices plutôt qu'une approche monolithique.

\subsection{Microservices}

Les architectures de microservices sont récemment apparues comme un nouveau paradigme pour la programmation d'applications \citep{Dragoni2017} et dont l'origine se base sur le concept d'\ac{AOS} \citep{MacKenzie2006}. Comme le montre la Figure \ref{fig:mono_micro}, cette approche suggère de diviser une application en un ensemble de services plus petits, indépendants et interconnectés. En comparaison aux applications monolithiques, où tous les composants logiciels se trouvent dans une seule instance, les services exécutent des fonctions plus détaillées et précises. Bien que les architectures monolithiques soient simples à implémenter, les architectures de microservices présentent, elles aussi, différents avantages. La première concerne l'\emph{agilité} des microservices. En effet, puisque les applications sont fragmentées au niveau le plus élémentaire de leurs fonctionnalités, chaque service devient individuellement plus facile à maintenir et beaucoup plus rapide à développer et à déployer. Le second avantage principal demeure la \emph{réutilisabilité}. Les microservices permettent aux développeurs de créer des applications en utilisant certains fragments déjà existants. De plus, la barrière entre les technologies (\textit{p. ex.} les langages de programmation) est réduite puisque les services fonctionnent de manière indépendante. En ce sens, cet \emph{agnosticisme technologique} permet d'obtenir des applications hétérogènes du point de vue des technologies dans leur conception. Par ailleurs, un autre avantage offert par les architectures

\begin{figure}[H]
	\centering
	\includegraphics[width=.8\linewidth]{chapter5/mono_micro.pdf}
		\caption{Comparaison entre les architectures monolithiques et de microservices selon un exemple d'application qui vise à résoudre un problème d'apprentissage machine par le biais d'une interface graphique.}
	\label{fig:mono_micro}
\end{figure}

\noindent de microservices concerne la mise à l'échelle des différents composants à mesure que la demande pour une application augmente. En cas de forte demande ponctuelle, il est possible soit d'augmenter la quantité de ressources allouées, soit d'augmenter le nombre d'instances pour les services les plus impactés, plutôt que pour l'intégralité de l'application. Il s'agit respectivement de l'\emph{extensibilité dynamique horizontale} et de l'\emph{extensibilité dynamique verticale}. Enfin, puisque les composants d'une application dans une architecture de microservices sont généralement distribués, l'application est en mesure de supporter les pannes au niveau des services qui la composent. En effet, lorsqu'un service est en panne, la fonctionnalité dont il est responsable devient inopérante, mais le fonctionnement du reste de l'application n'est pas altéré. De plus, il est possible de mettre en place différents mécanismes pour remédier aux défaillances inattendues afin d'augmenter la résilience et la \emph{fiabilité} de l'ensemble du système.

\begin{figure}[hb!]
	\centering
	\includegraphics[width=.8\linewidth]{chapter5/containers_vms.pdf}
		\caption{Les trois principales techniques de virtualisation pour la mise en place d'une architecture de microservices.}
	\label{fig:containers_vms}
\end{figure}

Actuellement, il existe de nombreuses façons de mettre en place une architecture de microservices, la plus courante étant l'utilisation d'outils de virtualisation tels que les machines virtuelles (\acsp{VM}) traditionnelles, les conteneurs ou les conteneurs à l'intérieur de \acsp{VM}. La Figure \ref{fig:containers_vms} fournit une représentation graphique de ces trois différentes implémentations. Même si le choix de la méthode de virtualisation n'affecte pas les possibilités offertes par les architectures de microservices, il existe des différences significatives entre l'utilisation de \acsp{VM} traditionnelles et les conteneurs qu'il semble important de détailler. La principale différence réside dans le fait que les conteneurs proposent une virtualisation au niveau du système d'exploitation alors que les \acsp{VM} offrent une virtualisation au niveau du matériel. En ce qui concerne les \acsp{VM}, l'hyperviseur permet de cloisonner des portions du matériel. En effet, son rôle est d'attribuer à chaque machine virtuelle les ressources nécessaires en fonction des ressources physiques du système hôte. De manière générale, il existe deux types d'hyperviseurs. Dans un premier temps, il y a les hyperviseurs de système natif qui s'exécutent directement sur le matériel du système hôte. En ce sens, ceux-ci prennent la place du système d'exploitation de l'hôte et planifient directement l'utilisation des ressources allouées aux machines virtuelles en fonction du matériel. Dans un second temps, les hyperviseurs hébergés fonctionnent comme une couche logicielle supplémentaire au sein du système d'exploitation hôte. Ainsi, ils permettent de dissocier les systèmes d'exploitation invités (virtualisés) du système d'exploitation hôte.

Alternativement, les conteneurs permettent aux instances virtuelles de partager un système d'exploitation hôte unique. Par conséquent, puisque les conteneurs n'ont pas à embarquer un système d'exploitation, les images virtualisées demeurent beaucoup plus légères que celles des \acsp{VM} traditionnelles. De plus, les conteneurs sont, au même titre que les \acsp{VM}, isolés du système hôte, c'est-à-dire, qu'ils s'exécutent dans des espaces séparés à la fois les uns des autres, mais également de certaines parties du système d'exploitation hôte. Une telle isolation permet donc une utilisation plus efficace des ressources. Enfin, les conteneurs sont très rapides à créer et à détruire puisqu'il n'est pas nécessaire de démarrer ou d'arrêter un système d'exploitation à chaque fois. En effet, les conteneurs s'occupent uniquement de compléter le processus dont ils sont en charge.

En somme, une \acs{VM} est une émulation d'un système informatique tandis que les conteneurs sont toutes les unités logicielles qui regroupent le code et toutes ses dépendances requises (\textit{p. ex.} les librairies ou les binaires) qui composent une application. De ce fait, celle-ci peut s'exécuter de façon fiable et rapide d'un environnement à un autre. Ces deux technologies ne sont pas incompatibles puisqu'il est possible de les utiliser ensemble. Cependant, l'exécution de conteneurs à l'intérieur de machines virtuelles est, la plupart du temps, le résultat de l'évolution d'environnements de virtualisation matures déjà existants. Généralement, les conteneurs sont exécutés directement sur le système hôte afin d'optimiser les performances et la latence ou de réduire les coûts des licences des outils de virtualisation et des systèmes d'exploitation.

\subsection{Organisation Matérielle}

L'organisation matérielle de l'implémentation de l'architecture d'habitats intelligents présentée dans ce chapitre est illustrée par la Figure \ref{fig:proposed_arch}. Afin de supporter l'architecture de microservices, cette organisation repose sur un ensemble de cinq n\oe{}uds principaux (\texttt{m0}, \texttt{m1}, \texttt{m2}, \texttt{w0} et \texttt{w1}), puisque ceci représente le nombre minimum de n\oe{}uds nécessaires pour former un \textit{cluster} distribué fiable. Par ailleurs, l'implémentation proposée suggère l'utilisation de deux  n\oe{}uds supplémentaires (\texttt{f0} et \texttt{f1}) sur chacun desquels une unité de stockage de type \acs{RAID} (\acl{RAID}) est interfacée. L'objectif de ces n\oe{}uds est de fournir un système de fichiers distribué à l'ensemble du \textit{cluster}. En effet, puisque certains conteneurs ont la capacité de monter différents volumes sur le système hôte, un tel système de fichiers offre un moyen fiable de partager des données entre chaque conteneur, quel que soit le n\oe{}ud sur lequel ils s'exécutent. En outre, tous les n\oe{}uds qui composent le \textit{cluster} et le système de fichiers distribué sont connectés à un commutateur réseau pour leur permettre de communiquer entre eux. De plus, l'ensemble de l'architecture est isolé à l'intérieur d'un réseau local afin de prévenir les problèmes de sécurité qui pourraient compromettre les expériences

\begin{figure}[H]
	\centering
	\includegraphics[width=\linewidth]{chapter5/proposed_arch.pdf}
        \caption{Organisation matérielle de l'architecture d'habitats intelligents proposée illustrant l'implémentation d'un \textit{cluster} pour le support de l'architecture de microservices ainsi que le système de fichiers distribué.}
	\label{fig:proposed_arch}
\end{figure}

\noindent et de préserver l'anonymat des participants. Toutefois, pour faciliter la configuration et la maintenance de l'architecture, cette dernière demeure accessible de manière ad hoc avec un ordinateur \textit{via} un routeur qui est, quant a lui, connecté à la fois au Web et au réseau local.

\subsection{Système de fichiers distribué}

Le système de fichiers distribué fourni par les n\oe{}uds \texttt{f0} et \texttt{f1} repose sur le protocole \ac{NFS}. Le principe de ce protocole reste simple, car il est implémenté selon le modèle client/serveur. Un serveur \acs{NFS} gère l'authentification, l'autorisation, l'administration des clients ainsi que les données. Ainsi, une fois autorisés, les clients NFS peuvent accéder aux données distantes de la même manière qu'ils le font localement. En ce sens, chaque n\oe{}ud qui compose le \textit{cluster} est autorisé à accéder (lecture) et à manipuler les fichiers (création, mise à jour, suppression) de manière classique. Néanmoins, tous les autres n\oe{}uds seront informés des changements qui en résultent.

Cependant, puisque l'idée est de proposer une architecture fiable, le fait de n'avoir qu'un seul serveur \acs{NFS} ne satisfaisait pas cette contrainte. En ce sens, l'outil \acs{DRDB}\footnote{\url{https://www.linbit.com/drbd/}} (\acl{DRDB}) a été mis en place afin que les n\oe{}uds \texttt{f0} et \texttt{f1} puissent proposer un système de fichiers à la fois distribué, mais aussi répliqué. \acs{DRDB} a été paramétré pour effectuer une réplication complète des données stockées entre le serveur principal (\texttt{f0}) et le serveur secondaire (\texttt{f1}), soit le même fonctionnement qu'un système de stockage de type \acs{RAID} 1 en réseau. Afin de favoriser l'intégrité des données plutôt que la vitesse de réplication, la mise en place d'une réplication synchrone constante entre le n\oe{}ud principal et le n\oe{}ud secondaire a été adoptée plutôt qu'une réplication asynchrone ou semi-synchrone. Ainsi, les opérations de manipulation des fichiers réalisées sur le n\oe{}ud principal ne sont considérées comme terminées que lorsque les écritures sur le disque local et sur le disque distant du n\oe{}ud secondaire sont confirmées par ce dernier. Néanmoins, \acs{DRDB} ne fournit aucune fonctionnalité relative à un quelconque mécanisme garantissant la fiabilité du système de fichiers en cas de panne d'un des deux n\oe{}uds. En ce sens, l'outil Heartbeat\footnote{\url{http://www.linux-ha.org/doc/man-pages/re-heartbeat.html}} a également été adopté dans cette implémentation. Cet outil permet de proposer un mécanisme permettant de garantir la haute disponibilité du système de fichiers distribué. En tant que processus d'arrière-plan, le logiciel vise à surveiller l'état des deux serveurs \acs{DRDB}. En cas de défaillance du n\oe{}ud principal (\texttt{f0}), l'adresse \ac{VIP} du système de fichiers distribué qui pointe vers \texttt{f0} est automatiquement réaffectée pour identifier le n\oe{}ud secondaire (\texttt{f1}). Ainsi, l'accès aux données n'est en aucun cas compromis lors de la perte d'un seul n\oe{}ud, puisque cette opération est effectuée de manière transparente pour les clients \acs{NFS}.

\subsection{Orchestration des conteneurs}

L'implémentation de l'architecture de microservices proposée dans ce chapitre repose d'abord sur le moteur de conteneurs Docker\footnote{\url{https://www.docker.com}}, qui a été installé sur chaque n\oe{}ud qui compose le \textit{cluster} (\texttt{m0}, \texttt{m1}, \texttt{m2}, \texttt{w0} et \texttt{w1}). De plus, afin de pouvoir mettre en place le \textit{cluster} distribué grâce à l'ensemble de ces n\oe{}uds, il était nécessaire d'utiliser un orchestrateur. L'orchestration de conteneurs fait référence à un ensemble de techniques qui permettent de gérer les différents cycles de vie des conteneurs ainsi que leurs environnements dynamiques. Plus précisément, les outils d'orchestration permettent d'automatiser plusieurs tâches telles que la configuration, l'ordonnancement, l'approvisionnement et la mise à l'échelle des conteneurs, mais également la répartition de charge, l'allocation des ressources et la sécurité des interactions entre les conteneurs. Il existe actuellement plusieurs outils d'orchestration de conteneurs populaires tels que Kubernetes\footnote{\url{https://kubernetes.io}}, Apache Mesos\footnote{\url{https://mesos.apache.org}} et Docker Swarm\footnote{\url{https://docs.docker.com/engine/swarm/}}. Pour notre architecture, c'est l'outil Docker Swarm qui a été adopté. Plusieurs facteurs ont motivé ce choix. Tout d'abord, cet outil est plus simple à mettre en place puisqu'il est conditionné, distribué et totalement intégré au moteur de conteneur qui est déjà utilisé. En outre, bien qu'il est considéré comme moins extensible parmi les trois outils mentionnés, celui-ci offre, tel que détaillé dans la suite de cette section, tous les mécanismes requis pour créer et gérer le \textit{cluster} de cette architecture.

De manière générale, un \textit{cluster} Docker Swarm est composé de plusieurs n\oe{}uds sur lesquels le moteur Docker est installé. Ces n\oe{}uds peuvent adopter deux types de rôles\textemdash un rôle de gestionnaire (\textit{manager}) ou un rôle de travailleur (\textit{worker}). Les n\oe{}uds de type \textit{manager} sont ceux qui reçoivent les fichiers de définition des services à exécuter au sein du \textit{cluster}. De plus, les \textit{managers} distribuent les tâches qui composent ces services aux n\oe{}uds de type \textit{worker}, en fonction de leurs fichiers de définition. Ainsi, ce sont les n\oe{}uds \textit{manager} qui sont responsables de l'orchestration et de la gestion du \textit{cluster}. Dans ce contexte, les services font référence à un ensemble de tâches, c'est-à-dire des conteneurs, qui doivent s'exécuter sur les n\oe{}uds travailleurs du \textit{cluster} pour réaliser un processus donné. Néanmoins, il est tout à fait possible de définir une politique de placement manuellement. Ainsi, un service peut être soit global, soit répliqué. Lorsqu'un service est global, une unique instance est déployée sur chaque n\oe{}ud du \textit{cluster} qui est disponible, et ce, sans tenir compte de son rôle.  À l'inverse, lorsqu'un service est répliqué, il est nécessaire de préciser, dans le fichier de définition, le nombre de répliques qui doivent être déployées ainsi que le type de n\oe{}uds sur lesquelles elles seront exécutées. Un des n\oe{}uds \textit{manager} est alors en charge d'établir cette répartition. Par ailleurs, afin que les n\oe{}uds \textit{manager} puissent suivre l'évolution de l'exécution des services, les n\oe{}uds travailleurs incluent un agent dont le rôle est de rendre compte, aux \textit{managers}, de l'état des services qui lui sont attribués. Par défaut, les n\oe{}uds \textit{manager} sont également des n\oe{}uds travailleurs, mais il est possible de les configurer de manière à ce qu'ils n'acceptent aucune charge de travail en plus de leurs tâches de gestion du \textit{cluster}.

En ce qui concerne les \textit{managers}, puisqu'ils représentent les n\oe{}uds les plus importants pour la stabilité du \textit{cluster}, il est nécessaire que ce dernier en comporte plusieurs. Plus précisément, préférablement un nombre impair, selon les recommandations préconisées par Docker Swarm. En effet, parmi tous les n\oe{}uds de type \textit{manager}, l'un d'entre eux est élu en tant que leader par tous les autres \textit{managers} selon une implémentation de l'algorithme de consensus Raft \citep{MacKenzie2006}. Ainsi, ce n\oe{}ud particulier est responsable de toutes les décisions pour l'ensemble du groupe de \textit{managers}. Bien qu'il n'y ait pas de limite quant au nombre de n\oe{}uds gestionnaires que peut admettre un \textit{cluster} Docker Swarm, la décision concernant l'effectif à mettre en place reste un compromis entre la performance et la tolérance aux pannes. En effet, si le n\oe{}ud élu comme leader du \textit{cluster} devient indisponible, n'importe quel autre \textit{manager} peut obtenir ce rôle si le quorum Raft, c'est-à-dire, un accord majoritaire entre les n\oe{}uds gestionnaires, est possible. Plus précisément, l'algorithme Raft tolère jusqu'à $\lfloor(N-1)/2\rfloor$ défaillances et exige un quorum de $\lfloor(N/2) + 1\rfloor$ membres pour permettre une décision, où $N$ fait référence au nombre de n\oe{}uds \textit{manager}. Il apparaît donc clairement qu'un tel processus peut créer une surcharge du trafic réseau avec un nombre élevé de \textit{managers}, impactant alors la performance globale du \textit{cluster}. En ce sens, nous avons opté pour un \textit{cluster} de cinq n\oe{}uds, soit trois gestionnaires et deux travailleurs, ceci dans le but de tolérer une défaillance complète d'un n\oe{}ud, quel que soit son rôle. De plus, un tel nombre de \textit{managers} permet de respecter la contrainte d'avoir un nombre impair de n\oe{}uds gestionnaires pour que le quorum demeure toujours valide en cas de panne.

Pour permettre aux conteneurs de communiquer entre eux au sein du \textit{cluster} Docker Swarm, un pilote réseau spécifique a été utilisé. Ce pilote permet de créer des réseaux superposés (\textit{overlay networks}) en s'appuyant sur la technologie de tunnelisation \ac{VXLAN} \citep{rfc7348} qui permet l'encapsulation de trames réseau de la couche 2 dans \acs{UDP} (couche 4). Ainsi, dans un contexte de virtualisation comme celui imposé par les conteneurs, ce pilote permet de simplifier la complexité de la gestion des différents réseaux virtuels nécessaires à la communication entre les conteneurs qui sont déployés de manière éparse sur les différents n\oe{}uds du \textit{cluster}. De plus, les réseaux superposés offrent des mécanismes qui permettent de s'assurer du bon fonctionnement de la redondance d'un point de vue réseau au sein du \textit{cluster}. Lorsqu'un \textit{cluster} Docker Swarm est initialisé, un réseau \textit{ingress} est automatiquement créé sur chaque n\oe{}ud. Il s'agit d'un réseau superposé particulier dont l'objectif est de faciliter la répartition de la charge des différents services entre les n\oe{}uds du \textit{cluster}. Il est ensuite possible de créer autant de réseaux superposés que nécessaire pour interconnecter les conteneurs qui ont besoin d'échanger des données.

Par ailleurs, un réseau de type pont (\textit{bridge network}) est également créé automatiquement sur chaque n\oe{}ud lors de l'initialisation du \textit{cluster}. Ces réseaux sont nécessaires pour relier tous les réseaux superposés (y compris le réseau \textit{ingress}) au réseau physique des n\oe{}uds du \textit{cluster}. Par conséquent, comme les réseaux de type pont se situent au-dessus de la couche réseau du système hôte, une communication entre les conteneurs interconnectés par un réseau superposé, mais s'exécutant dans des n\oe{}uds différents, est rendue possible. Par défaut, ces communications sont chiffrées à l'aide de l'algorithme AES-GCM \citep{rfc5288}. Les n\oe{}uds \textit{manager} du cluster assurent le remplacement de la clé de chiffrement qu'ils partagent toutes les douze heures, ceci dans le but d'assurer un niveau de sécurité acceptable sans pour autant compromettre les performances des communications réseau.

Puisque les réseaux superposés attribuent dynamiquement une adresse \acl{VIP} à chaque conteneur lors de leur création, ceux-ci sont isolés d'un point de vue du réseau, ce qui simplifie donc la consommation des services. Toutefois, lorsque le nombre de services devient important, il peut sembler pertinent de connaître à l'avance certaines \acsp{VIP}, ce qui n'est évidemment pas possible. Pour résoudre ce problème, l'orchestrateur Swarm propose un mécanisme de découverte de services. Cette fonctionnalité repose sur un serveur DNS qui est intégré dans le moteur de conteneur de chaque n\oe{}ud. Ce dernier est alors chargé de résoudre le nom des services pour permettre le routage des requêtes réseau vers les conteneurs correspondants grâce à leurs \acsp{VIP} associées. En d'autres termes, le nom d'un service donné peut, par exemple, être utilisé en remplacement de son adresse \acl{VIP} dans un fichier de configuration. Ainsi, cette référence est interprétée correctement grâce au processus de découverte de services dès lors que la \acs{VIP} est fixée.

Néanmoins, lorsque les services sont répliqués, le mécanisme de découverte de services seul n'est plus suffisant. En ce sens, grâce à l'orchestrateur,  un mécanisme de répartition est mis en place dans le but de déterminer quelle réplique d'un service en particulier est utilisée. Ainsi, Docker Swarm s'appuie sur le protocole \ac{IPVS}, une implémentation de la répartition de charge qui est déjà intégrée au niveau de la couche réseau transport du noyau Linux. Grâce à ce protocole, les requêtes \acs{TCP}/\acs{UDP} inter-services peuvent donc être redirigées correctement vers les conteneurs appropriés. Dans le cas spécifique d'un \textit{cluster} Docker Swarm, chaque n\oe{}ud écoute sur les ports qui sont exposés par les services qui doivent être accessibles à distance depuis un environnement extérieur (\textit{p. ex.} un tableau de bord web qui écoute sur le port \texttt{8080}). Ensuite, \acs{IPVS} applique une répartition de la charge selon l'algorithme Round-Robin \citep{Ghaffarinejad2014} pour transmettre la demande à l'une des instances actives du service en question. Comme le montre la Figure \ref{fig:swarm_load_balancing}, si le n\oe{}ud sollicité ne contient aucune réplique du service demandé par un client, alors \acs{IPVS} va router la requête à une réplique active présente sur un autre n\oe{}ud, ce qui est possible grâce au réseau superposé de type \textit{ingress}.

\begin{figure}[H]
	\centering
	\includegraphics[width=.8\linewidth]{chapter5/swarm_load_balancing.pdf}
        \caption{Exemple du fonctionnement de la répartition de la charge selon l'algorithme Round-Robin appliquée par le protocole \acs{IPVS} sur lequel repose Docker Swarm où un des itinéraires possibles pour une requête faite sur le service répliqué \texttt{App} est identifié par des flèches rouges.}
	\label{fig:swarm_load_balancing}
\end{figure}

\subsection{Proxy inverse}

Puisque notre architecture est composée d'un \textit{cluster} de cinq n\oe{}uds, tous les services qui y sont déployés demeurent accessibles \textit{via} cinq points d'entrée différents, étant donné que l'orchestrateur ouvre tous les ports de ces services sur chacun des n\oe{}uds du \textit{cluster}. Cependant, avec un nombre important de services, il peut s'avérer difficile de gérer quel service est publié sur quel port. Ainsi, puisque la répartition de la charge au niveau des services est réalisée \textit{via} l'orchestrateur, il semble indispensable de proposer une répartition de la charge au niveau des n\oe{}uds également. Ceci dans le but de proposer un accès externe unifié et sécurisé aux services internes par le biais d'une \acs{URL} (\acl{URL}) telle que \texttt{https://service.domain.com}. Pour ce faire, l'outil open-source Tr\ae{}fik\footnote{\url{https://traefik.io}} a été préféré à d'autres options telles que NGINX\footnote{\url{https://www.nginx.com}} ou HAProxy\footnote{\url{https://www.haproxy.org}}, car il est le mieux adapté aux architectures basées sur des microservices. En effet, le principal avantage de Tr\ae{}fik est sa capacité à découvrir automatiquement les informations réseau et les services disponibles dans le \textit{cluster} et à mettre à jour dynamiquement sa configuration en fonction de l'évolution de l'environnement. Ces fonctionnalités sont particulièrement importantes avec l'utilisation de  microservices, car ceux-ci sont généralement sans état (\textit{stateless}), mais aussi car leur durée de vie est souvent courte et de nouvelles versions peuvent avoir à être déployées fréquemment. De plus, leurs instances peuvent être mises à l'échelle de façon dynamique en fonction de l'augmentation de la demande.

Tr\ae{}fik est considéré comme un proxy inverse, c'est-à-dire le principal point d'entrée d'un réseau privé. En effet, les proxys inverses sont, la plupart du temps, placé derrière un pare-feu et leur rôle est d'acheminer les requêtes entrantes des clients vers un des n\oe{}uds du \textit{cluster} et le service correspondant. En outre, les proxys inverses peuvent également remplir un certain nombre d'autres fonctions importantes pour améliorer l'efficacité et la sécurité des systèmes sur lesquels ils sont mis en place. Tout d'abord, en ce qui concerne Tr\ae{}fik, ce dernier fournit une répartition de la charge au niveau des n\oe{}uds ce qui permet de répartir les requêtes à l'ensemble des n\oe{}uds actifs au sein du \textit{cluster} pour éviter que l'un d'entre eux ne soit saturé. De plus, cet outil permet également de masquer l'organisation interne de l'architecture, car il apporte une couche supplémentaire de protection en ne dévoilant jamais l'adresse IP du n\oe{}ud qui traite réellement les requêtes. Enfin, toujours dans une optique d'offrir une meilleure protection, les proxys inverses, et plus particulièrement Tr\ae{}fik, permettent de chiffrer les échanges de données entre les clients et les services de l'architecture grâce à un ou plusieurs certificats \acs{TLS} associés aux différents services ou sous-domaines. La Figure \ref{fig:arch_reverse_proxy} illustre un exemple de ce fonctionnement. En effet, Tr\ae{}fik propose un point d'entrée unique qui permet d'accéder au service \texttt{App} \textit{via} une \acs{URL} sécurisée : \texttt{https://liara.uqac.ca/app}. Ainsi lorsque cette requête est soumise par le client (\textit{p. ex. } un navigateur web), le répartiteur interne de Tr\ae{}fik achemine la requête vers l'une des répliques actives du service \texttt{App}. Dans ce scénario, la répartition de la charge fournie par l'orchestrateur Docker Swarm n'est pas représentée pour simplifier la figure, mais celle-ci demeure tout de même active et opérationnelle. En effet, bien que Tr\ae{}fik ait routé la requête vers le \texttt{n\oe{}ud 1}, il est possible que le répartiteur de charge du \textit{cluster}, quant à lui, achemine en interne la demande vers la \texttt{réplique 0} du service \texttt{App} qui s'exécute sur le \texttt{n\oe{}ud 0}.

\begin{figure}[H]
	\centering
	\includegraphics[width=.8\linewidth]{chapter5/arch_reverse_proxy.pdf}
        \caption{Exemple du fonctionnement du proxy inverse Tr\ae{}fik lorsqu'une requête pour accéder au service \texttt{App} est effectuée par un client \textit{via} une \acs{URL} sécurisée.}
	\label{fig:arch_reverse_proxy}
\end{figure}

\subsection{Gestion du \textit{cluster}}

Le moteur de conteneurs Docker incluant l'orchestrateur Docker Swarm est un outil qui est utilisé à travers une interface en ligne de commandes \acs{CLI}. Ainsi, il demeure possible d'initialiser et de gérer le \textit{cluster} Docker Swarm qui régit notre architecture selon plusieurs méthodes. La plupart du temps, la méthode d'initialisation la plus appropriée consiste en l'utilisation d'un outil de gestion de configuration tel qu'Ansible\footnote{\url{https://www.ansible.com}} qui permet d'automatiser les tâches d'administration de systèmes. Cependant, comme notre architecture admet une taille raisonnable et demeure relativement simple, nous avons choisi d'initialiser le \textit{cluster} manuellement grâce à divers scripts shell et fichiers de configuration. En effet, alors que les outils d'automatisation offrent une meilleure gestion des flux opérationnels d'administration de systèmes complexes ainsi qu'une meilleure flexibilité globale, les scripts shell nous ont semblé être le meilleur compromis à adopter étant donné le contexte encore expérimental de cette architecture.

Par ailleurs, la gestion du \textit{cluster} au quotidien \textit{via} une interface en ligne de commandes a été jugée trop contraignante. De ce fait, le logiciel open-source Portainer\footnote{\url{https://www.portainer.io}} a été déployé comme un service à part entière au sein du \textit{cluster}. Grâce à une interface graphique (\acl{GUI} ou \acs{GUI}) conviviale et soignée montrée par la Figure \ref{fig:portainer}, cet outil nous a permis

\begin{figure}[H]
	\centering
	\includegraphics[width=\linewidth]{chapter5/portainer.jpg}
        \caption{Interface Graphique de l'outil Portainer déployé pour permettre la gestion du \textit{cluster}.}
	\label{fig:portainer}
\end{figure}

\noindent de simplifier considérablement la tâche de gestion du \textit{cluster}. En effet, celle-ci a permis de réduire le risque d'erreurs induit par la complexité de certaines commandes nécessaires au pilotage du moteur de conteneurs. De plus, le choix de Portainer comme outil de gestion a également été motivé par son large éventail de fonctionnalités. Les plus importantes comprennent la gestion des images, des réseaux et des volumes de conteneurs, mais cet outil propose également une visualisation des n\oe{}uds du \textit{cluster} incluant le placement de chaque conteneur, la consultation de tous les fichiers journaux de chaque conteneur ainsi que la possibilité d'augmenter ou en diminuer le nombre de répliques pour chaque service en fonction de la charge.

\subsection{Base de données répliquée}

Puisque cette architecture est conçue principalement pour les maisons intelligentes, il était important de proposer un moyen fiable de stocker les valeurs des capteurs ainsi que l'état des effecteurs. Pour ce faire, trois services ont été déployés sur le \textit{cluster}, chacun contenant une instance du \ac{SGBD} MongoDB\footnote{\url{https://www.mongodb.com}}. Ainsi, la réplication des données a été réalisée grâce à une architecture composée d'un ensemble de répliques (\textit{replica set}) à trois membres.

MongoDB est un \acs{SGBD} open-source orienté documents et non relationnel (\acs{NoSQL}), principalement utilisé pour le stockage de gros volumes de données. Un tel choix a été fait, car sa conception est axée sur la performance, la haute disponibilité et la mise à l'échelle automatique. Puisqu'il s'agit d'un \acs{SGBD} orienté document, les données sont stockées dans des collections sous forme d'ensembles de documents. Ceux-ci font référence à une structure de données composée de paires de champs et de valeurs. En effet, ils sont formatés en \ac{BSON}, un format de fichier similaire aux objets \acs{JSON} où les champs peuvent également inclure d'autres documents, des tableaux et des ensembles de documents. Ce type de modèle de base de données dit semi-structuré implique qu'il n'existe pas de séparation entre les données et le schéma qui les représente. Ainsi, le principal avantage de l'approche orientée documents reste d'abord la possibilité de représenter des relations hiérarchiques complexes avec un seul enregistrement. Aussi, de tels modèles de données facilitent la répartition des données entre plusieurs n\oe{}uds de base de données, ce qui simplifie le processus de mise à l'échelle.

Dans le contexte de MongoDB, un ensemble de répliques constitue un groupe d'instances de base de données qui maintiennent le même ensemble de données en fournissant de la redondance ainsi qu'une haute disponibilité pour garantir la tolérance aux pannes. Le déploiement d'un tel ensemble peut se faire principalement selon deux types d'architectures différentes. Dans un premier cas, l'architecture est composée au minimum d'un n\oe{}ud principal et de deux n\oe{}uds secondaires. Le second type d'architecture, quant à lui, reprend les mêmes caractéristiques du premier type, mais doit également admettre un n\oe{}ud arbitre. Un n\oe{}ud principal est le seul membre d'un ensemble qui tolère les opérations d'écriture. Les n\oe{}uds secondaires sont, quant à eux, en charge de préserver une copie de l'ensemble de données du n\oe{}ud principal. Afin que le processus de réplication se déroule correctement, les n\oe{}uds secondaires appliquent les instructions du journal des opérations du n\oe{}ud principal à leur propre ensemble de données, et ce, de manière asynchrone. En revanche, dans une architecture d'ensemble de répliques qui contient un arbitre, ce dernier ne dispose pas de copie de l'ensemble de données du n\oe{}ud principal. Ainsi, le n\oe{}ud arbitre ne peut, d'aucune façon, devenir un n\oe{}ud principal en cas de panne de ce dernier. Toutefois, le n\oe{}ud arbitre participe à l'élection d'un nouveau n\oe{}ud principal lorsque cela est nécessaire. En ce sens, dans le cas d'un ensemble de répliques à trois membres, la mise en \oe{}uvre d'une architecture composée d'un n\oe{}ud principal et de deux n\oe{}uds secondaires a été préférée. En effet, le fait de remplacer un n\oe{}ud secondaire par un arbitre ne permet pas de garantir une aussi bonne répartition de la charge lors des opérations de lecture des données.

La Figure \ref{fig:mongodb_replication} illustre le fonctionnement de cette architecture d'ensemble de répliques composée d'un n\oe{}ud principal et de deux n\oe{}uds secondaires (P-S-S). Toutes les deux secondes, tous les n\oe{}uds s'envoient des pouls (\texttt{A}); dans le cas où l'un d'entre eux ne revient pas à son émetteur dans les dix secondes, les n\oe{}uds restants identifient alors le n\oe{}ud non réactif comme inaccessible (\texttt{B}). Lorsque c'est le n\oe{}ud principal qui est indisponible, un processus d'élection est alors déclenché pour que l'un des deux n\oe{}uds secondaires devienne le nouveau n\oe{}ud principal (\texttt{C}). De la même manière que pour l'orchestration du \textit{cluster}, la recommandation qui est formulée dans la documentation pour déployer un ensemble de répliques MongoDB est de mettre en place un nombre total de n\oe{}uds impair. Ainsi, il est possible, dans le cas d'une architecture P-S-S comme celle-ci, de subir la perte totale d'une

\begin{figure}[H]
	\centering
	\includegraphics[width=.9\linewidth]{chapter5/mongodb_replication.pdf}
        \caption{Processus d'élection avec la base de données MongoDB selon l'architecture d'ensemble de répliques à trois n\oe{}uds de type P-S-S où \texttt{A}, \texttt{B} et \texttt{C} représentent respectivement les étapes successives lors de la perte totale du n\oe{}ud principal.}
	\label{fig:mongodb_replication}
\end{figure}

\noindent instance de la base de données. En effet, les quorums de tolérance aux pannes demeurent identiques pour les deux composants logiciels.

\subsection{Dépôt d'images de conteneurs}

Le principal avantage de l'utilisation d'une architecture de microservices, en particulier dans un environnement comme celui des laboratoires de recherche dans le domaine des habitats intelligents, est de fournir un moyen simple de déployer des composants logiciels expérimentaux qui fonctionnent dans des conteneurs pour réaliser la reconnaissance d'activités. Ainsi, dans le but de faciliter la gestion de versions (\textit{versionning}), la distribution et la réutilisation de ces composants, un système de stockage des images des conteneurs a été mise en place au sein du \textit{cluster}.

Les images sont des fichiers immuables qui sont composés de plusieurs couches contenant le code source, les librairies, les dépendances ainsi que les outils nécessaires au bon fonctionnement des conteneurs. En d'autres termes, les images décrivent les services et leur environnements virtuels à un instant donné. En fin de compte, les conteneurs ne représentent que des images qui sont en cours d'exécution. En ce sens, celles-ci peuvent être stockées dans un dépôt, où les répertoires qu'il admet contiennent les différentes versions pour chacune des images. Grâce à un tel registre, il devient possible pour les expérimentateurs de télécharger certaines images (\textit{pull}), d'en créer (\textit{push}) de nouvelles contenant leurs propre composants logiciels ou de créer de nouvelles versions d'images déjà existantes. Par défaut, le moteur de conteneurs installé sur chaque n\oe{}ud de l'architecture est configuré pour utiliser le dépôt public DockerHub\footnote{\url{https://hub.docker.com}}. Cependant, puisque les applications expérimentales conçues dans les environnements de recherche peuvent contenir des vulnérabilités, des informations confidentielles ou un certain nombre d'innovations, la configuration du moteur de conteneurs a été modifiée afin que ce dépôt privé d'images puisse être utilisé dans le \textit{cluster}.

\subsection{Organisation des conteneurs}
\label{sec:cont_org}

Pour résumer les différents aspects qui décrivent la conception de l'architecture proposée et qui ont été introduits dans ce chapitre, la Figure \ref{fig:containers} propose une représentation graphique du déploiement des conteneurs sur les n\oe{}uds qui composent le cluster. De plus, les réseaux superposés pour chaque service y sont également illustrés.

\begin{figure}[H]
	\centering
	\includegraphics[width=.9\linewidth]{chapter5/containers.pdf}
        \caption{Déploiement des conteneurs sur les n\oe{}uds du \textit{cluster} qui décrivent la conception de l'architecture proposée.}
	\label{fig:containers}
\end{figure}

Dans ce déploiement, il est possible de voir que l'application Tr\ae{}fik admet deux services distincts. Le premier concerne le service de proxy inverse dont trois répliques sont exécutées sur chacun des n\oe{}uds de gestion du \textit{cluster} (\texttt{m0}, \texttt{m1}, \texttt{m2}). Ce placement a été privilégié, car cela permet de s'assurer de la fiabilité d'un élément aussi important en cas de perte d'un \textit{manager}. Le second service est, quant à lui, le tableau de bord web qui permet de visualiser, en temps réel, les routes actives vers les différents services ouverts à un environnement extérieur qui sont détectées par l'outil. De plus ce tableau de bord permet de visualiser plusieurs statistiques d'accès pertinentes pour l'évaluation de la charge en fonction des services. Néanmoins, puisque ce tableau de bord n'a pas un impact majeur sur le bon fonctionnement du cluster, son déploiement n'admet aucune réplique supplémentaire au seul conteneur qui lui est attribué. Toutefois, ce service est doté d'une politique de redémarrage qui prévoit de toujours relancer le conteneur si son exécution est interrompue. En ce sens, s'il se produit une défaillance au niveau du n\oe{}ud sur lequel il est déployé (\texttt{m0}), l'exécution du conteneur du tableau de bord de Tr\ae{}fik peut être relancée soit sur \texttt{m1}, soit sur \texttt{m2}. De la même manière, des instructions de déploiement identiques ont été définies pour le service du dépôt d'images et le service du tableau de bord de l'outil de gestion du \textit{cluster}.

Par ailleurs, en ce qui concerne la base de données, l'ensemble de répliques MongoDB a été déployé sur les n\oe{}uds de gestion dans le but de fournir, en permanence, une réplication sûre des données et de tolérer, au maximum, la défaillance d'un unique n\oe{}ud. Enfin, puisque le rôle de l'outil Portainer est de pouvoir gérer l'intégralité du \textit{cluster}, un agent, c'est-à-dire, un service global a été déployé sur chaque n\oe{}ud pour permettre à l'application web de transmettre les bonnes requêtes aux différents moteurs de conteneurs présents sur chacun des n\oe{}uds.

En ce qui concerne la communication réseau, un réseau superposé a été créé pour chaque service. De plus, le tableau de bord du proxy inverse est automatiquement exposé et accessible \textit{via} l'\acs{URL} suivante : \texttt{https://liara.uqac.ca/proxy}. Toutefois, puisque le tableau de bord de l'outil de gestion du \textit{cluster} et le dépôt d'images doivent également être accessibles depuis l'extérieur du \textit{cluster}, ces services sont connectés au réseau superposé du proxy inverse. Ainsi, le routage des demandes clients en ce qui concerne les accès à ces services est rendu possible \textit{via} les \acsp{URL} suivantes : \texttt{https://liara.uqac.ca/cluster} et \texttt{https://liara.uqac.ca/registry}.

\section{Experimentations}

Afin d'évaluer et de valider l'architecture introduite dans les sections précédentes, une installation expérimentale préliminaire a été déployée dans notre laboratoire, le \acs{LIARA}. En outre, plusieurs expérimentations ont été réalisées afin de confirmer la capacité pour ce système à résister à différentes défaillances qui pourraient survenir afin d'en déterminer sa fiabilité globale. Pour ce faire, cette section commence par décrire la mise en \oe{}uvre matérielle utilisée pour le fonctionnement de l'architecture. Une seconde section décrit les expérimentations qui ont été menées ainsi que les résultats qui en découlent.

\subsection{Installation Matérielle}

Afin de minimiser les difficultés dans la reproduction du déploiement de l'architecture présentée de ce chapitre ainsi que les expérimentations qui y ont été appliquées, la mise en \oe{}uvre de cette architecture a été faite en utilisant du matériel open-source. Pour ce faire, notre choix s'est basé sur l'utilisation de sept \acsp{SOC} Raspberry Pi 3 Model B, un routeur sans fil conventionnel (LinkSys WRT1900AC) fonctionnant avec le système d'exploitation OpenWRT\footnote{\url{https://openwrt.org}} ainsi qu'un simple commutateur réseau. Le principal avantage de l'utilisation des Raspberry Pi est qu'elles offrent un rapport qualité-prix intéressant pour les besoins de cette architecture. En effet, alors que leur coût unitaire est de 35 dollars US, celles-ci intègrent un processeur ARMv8 quadric\oe{}ur de 1,2 GHz et 1 GiB de SDRAM. De plus, pour que ce déploiement expérimental reste aussi peu onéreux que possible, le stockage n'a pas été effectué sur des systèmes RAID. Au lieu de cela, deux clés USB ont été connectées aux deux Raspberry Pi utilisées pour le système de fichiers distribué (\texttt{f0} et \texttt{f1}).

De plus, comme ce modèle en particulier de Raspberry Pi dispose d'un processeur basé sur l'architecture ARMv8, l'utilisation de systèmes d'exploitation 64-bits y est supportée. En ce sens, nous avons opté pour une version spécifique de la distribution Linux Debian\footnote{\url{https://www.debian.org}} qui a été modifiée selon nos besoins\footnote{\url{https://github.com/FlorentinTh/FlOS}}. Ce choix a été établi considérant que le système d'exploitation Raspberry Pi OS\footnote{\url{https://www.raspberrypi.org/downloads/raspberry-pi-os/}} n'est toujours pas disponible en version 64-bits malgré la sortie de nouvelles Raspberry Pi disposant de plusieurs gibibits de SDRAM. Puisque les conteneurs virtualisent leurs environnements au niveau du système hôte, l'emploi d'un système d'exploitation 64-bits était péremptoire. En effet, plusieurs outils qui sont requis dans la conception de notre architecture étaient disponibles uniquement pour l'architecture de processeur ARMv8 (\textit{p. ex.} MongoDB).

\subsection{Haute disponibilité}

Suivant l'initialisation du \textit{cluster} Docker Swarm sur chacun des cinq n\oe{}uds de l'architecture (\texttt{m0}, \texttt{m1}, \texttt{m2}, \texttt{w0}, \texttt{w1}), tous les composants applicatifs y ont été déployés selon la politique de placement définie en Section \ref{sec:cont_org}. Ainsi, l'architecture distribuée a été opérationnelle en seulement quelques minutes. Cette politique de déploiement a été spécifiquement déterminée pour supporter la défaillance totale d'un n\oe{}ud au maximum. Cependant, bien que l'ajout de n\oe{}uds supplémentaires au \textit{cluster} doit irréfutablement améliorer la tolérance aux pannes, avoir tous ces n\oe{}uds dans le même emplacement géographique n'améliorent, en réalité, pas la fiabilité de l'ensemble du système. De plus, cela créera un environnement beaucoup plus complexe à gérer et à maintenir. Par conséquent, les différentes expérimentations réalisées sur cette architecture ont pour but de confirmer que cette implémentation demeure fiable.

Le premier protocole expérimental mis en place est relativement simple. La défaillance d'un n\oe{}ud a été simulée en débranchant son câble Ethernet au niveau du commutateur réseau afin que celui-ci ne puisse plus communiquer avec le reste du \textit{cluster}. En ce sens, nous avons commencé par déconnecter un seul n\oe{}ud de type \textit{worker} (\texttt{w0}). Cette expérimentation est identifié : \textit{\texttt{F0}}. Comme qu'attendu, tous les services déployés au sein de l'architecture sont restés accessibles et tous les conteneurs qui fonctionnaient sur \texttt{w0} ont été automatiquement répartis et relancés sur les n\oe{}uds opérationnels restants. Enfin, après avoir reconnecté ce n\oe{}ud au réseau, il a montré un état opérationnel en quelques secondes. Cependant, les conteneurs qui s'exécutaient auparavant sur \texttt{w0} n'ont pas été redémarrés sur ce n\oe{}ud d'origine, car ceux-ci étaient pleinement opérationnels sur les autres n\oe{}uds. Dans un second temps, lorsqu'un unique n\oe{}ud de gestion (\textit{manager}) a été débranché du réseau (\texttt{m2}), les mêmes résultats ont été observés (\textit{\texttt{F1}}). En revanche, lorsque le n\oe{}ud leader (\texttt{m0}) a été privé de sa connexion réseau, le processus d'élection s'est enclenché et c'est le n\oe{}ud \texttt{m2} qui a été choisi comme nouveau leader (\textit{\texttt{F2}}). Ensuite, deux n\oe{}uds de différents types ont été débranchés du commutateur réseau, soit un n\oe{}ud \textit{manager} (\texttt{m1}) ainsi qu'un \textit{worker} (\texttt{w0}), tandis que les autres sont restés connectés (\textit{\texttt{F6}}). Bien qu'avec cette architecture notre objectif était de tolérer la défaillance d'un n\oe{}ud uniquement, le bon fonctionnement du \textit{cluster} n'a pas été altéré dans cette situation. Cela peut s'expliquer par le fait que le dysfonctionnement a été simulé sur deux n\oe{}uds ayant un rôle différent. En effet, la reproduction de cette expérimentation en débranchant le câble réseau de deux n\oe{}uds gestionnaires incluant le leader (\textit{p. ex.} \texttt{m0} et \texttt{m1} ou \texttt{m0} et \texttt{m2}) a permis de constater que l'intégrité de l'ensemble de l'architecture était compromise (\textit{\texttt{F7}}). Bien que les services démarrés sur les n\oe{}uds travailleurs ont continué leur exécution normalement, la capacité, au sein du \textit{cluster}, d'effectuer des tâches de gestion, y compris le démarrage de nouveaux services était perdue. En ce sens, cette expérimentation nous permet d'affirmer qu'étant donné la mise en \oe{}uvre proposée, il demeure plus sûr de garder à l'esprit que la défaillance d'un seul n\oe{}ud reste la limite maximale à supporter, puisque selon leur type, la perte de deux n\oe{}uds peut potentiellement compromettre le bon fonctionnement du \textit{cluster}.

Dans un second temps, la procédure expérimentale précédente a été reproduite en simulant la défaillance des n\oe{}uds \textit{via} une déconnexion de leur alimentation électrique pour les arrêter, au lieu de les déconnecter du réseau (\textit{\texttt{F3}}, \textit{\texttt{F4}}, \textit{\texttt{F5}}). Bien que des résultats similaires aient été observés, le temps de récupération qui a été constaté pour chaque n\oe{}ud était plus important, c'est-à-dire, quelques minutes au lieu de quelques secondes. De plus, une expérimentation supplémentaire a été menée afin d'évaluer la résilience du \textit{cluster} en cas de coupure générale de l'alimentation électrique (\textit{\texttt{F8}}). Pour ce faire, toutes les Raspberry Pi ont été mises hors tension à l'aide du disjoncteur présent sur la multiprise à laquelle elles étaient branchées. Le routeur et le commutateur réseau, quant à eux, sont restés sous tension. Ainsi, puisque l'état du \textit{cluster} est préservé grâce à un mécanisme interne du moteur de conteneurs, le \textit{cluster} a pu restaurer son état de fonctionnement initial lui-même, après le redémarrage de chaque n\oe{}ud et le rétablissement de la communication inter-gestionnaires. Le temps de total récupération observé pour une telle coupure générale a été d'environ une dizaine de minutes. Le Tableau \ref{tab:expe_recap} présente un récapitulatif de ces expérimentations ainsi que les résultats qui ont été obtenus.

\begin{table}[H]
  \centering
  \caption{Récapitulatif des expérimentations réalisées sur l'architecture afin de déterminer sa fiabilité globale.}
  \label{tab:expe_recap}
  \resizebox{\textwidth}{!}{
    \begin{tabular}{@{}rcccccc@{}}
      \toprule
        \multicolumn{1}{l}{} & \textit{\texttt{F0}}, \textit{\texttt{F3}} & \textit{\texttt{F1}}, \textit{\texttt{F4}} & \textit{\texttt{F2}}, \textit{\texttt{F5}} & \textit{\texttt{F6}} & \textit{\texttt{F7}} & \textit{\texttt{F8}} \\
      \midrule
        \textbf{N\oe{}ud(s)} & \texttt{w0} & \texttt{m2} & \texttt{m0} & \texttt{m1} \& \texttt{w0} & \texttt{m0} \& \texttt{m1} & \texttt{tous} \\
        \multirow{1}{*}{\textbf{Type de panne}} & \begin{tabular}[c]{@{}c@{}}réseau \\[-15pt] - \\[-15pt] électrique\end{tabular} & \begin{tabular}[c]{@{}c@{}}réseau \\[-15pt] - \\[-15pt] électrique\end{tabular} & \begin{tabular}[c]{@{}c@{}}réseau \\[-15pt] - \\[-15pt] électrique\end{tabular} & \begin{tabular}[c]{@{}c@{}}réseau \\[-15pt] - \\[-15pt] électrique\end{tabular} & \begin{tabular}[c]{@{}c@{}}réseau \\[-15pt] - \\[-15pt] électrique\end{tabular} & électrique \\
      \midrule
        \textbf{Tâches relancées} & oui & oui & oui & oui & non & non \\
        \textbf{Élection d'un leader} & non & non & oui & non & non & non \\
      \midrule
        \textbf{État du cluster} & disponible & disponible & disponible & disponible & H.S. & disponible \\
        \multirow{1}{*}{\textbf{Temps de récupération}}  & \begin{tabular}[c]{@{}c@{}}$\approx 1\: s$ \\[-15pt] - \\[-15pt] $\approx 1\: m$\end{tabular}  & \begin{tabular}[c]{@{}c@{}}$\approx 1\: s$ \\[-15pt] - \\[-15pt] $\approx 1\: m$\end{tabular} & \begin{tabular}[c]{@{}c@{}}$\approx 1\: s$ \\[-15pt] - \\[-15pt] $\approx 1\: m$\end{tabular} & \begin{tabular}[c]{@{}c@{}}$\approx 1\: s$ \\[-15pt] - \\[-15pt] $\approx 1\: m$\end{tabular} & - & $\approx 10\: m$ \\
      \bottomrule
    \end{tabular}
  }
\end{table}

Finalement, ces deux expériences ont prouvé que l'architecture proposée dans ce chapitre offre une fiabilité globale plus que satisfaisante. En effet, selon les situations de défaillances, elle a su démontrer sa capacité à toujours supporter la défaillance d'un n\oe{}ud. Cependant, comme les pannes électriques peuvent impliquer un temps de récupération plus long, nous suggérons que tout l'équipement nécessaire au déploiement de cette architecture soit alimenté électriquement par une source d'\ac{ASI}.

\section{Conclusion}

Dans ce chapitre, une nouvelle architecture pour les maisons intelligentes a été proposée. Par opposition aux architectures existantes, cette implémentation vise à être agnostique vis-à-vis de la conception des applications qu'elle admet, mais également fiable et évolutive. Ainsi, la conception qui a été proposée repose sur le concept de microservices mis en \oe{}uvre grâce à un \textit{cluster} composé de cinq n\oe{}uds distribués. L'utilisation de microservices permet d'améliorer à la fois l'interopérabilité entre les applications d'apprentissage machine qui constituent généralement un ensemble hétérogène de technologies, ainsi que leur réutilisabilité.

De plus, cette implémentation a été conçue pour être compatible avec la majorité des architectures de maisons intelligentes existantes, car elle peut facilement remplacer l'unité centrale de calcul (serveur ou un \textit{broker}) que celles-ci admettent. Aussi, cette architecture s'inscrit dans la continuité de l'objectif qui consiste à supprimer complètement tout point de défaillance unique au sein des habitats intelligents afin que ceux-ci puissent offrir un niveau de fiabilité plus élevé à leurs résidents.

Enfin, le dernier objectif de cette implémentation concerne la possibilité d'y ajouter des ressources supplémentaires, tant matérielles que logicielles, en fonction des besoins. Ainsi, cette architecture permet, lorsqu'elle est déployée dans un environnement de recherche, un plus grand niveau d'évolutivité, ce qui permet alors de simplifier les procédures d'expérimentations. Grâce aux évaluations qui ont été réalisées pour évaluer la haute disponibilité de cette architecture, nous avons montré que le bon fonctionnement de l'ensemble du système n'était pas affecté lors d'un dysfonctionnement complet d'un n\oe{}ud du \textit{cluster}. De plus, ces expérimentations ont également permis de révéler que l'architecture était également résistante à une panne de courant généralisée. Néanmoins, puisque le temps de récupération du \textit{cluster} après une panne électrique demeure important, il est important de suggérer l'utilisation d'une alimentation sans interruption pour prévenir ce genre de situations.
